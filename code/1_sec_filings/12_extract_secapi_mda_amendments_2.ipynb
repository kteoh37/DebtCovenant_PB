{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify changes in contractual terms disclosed in MDA section following covenant violations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "import warnings\n",
    "import re\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "from nltk.stem import PorterStemmer\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "#setup\n",
    "\n",
    "s3_resource = boto3.resource('s3')\n",
    "\n",
    "# directories\n",
    "bucket = '[your-s3-bucket-name]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate expect keywords\n",
    "\n",
    "def stem_words(wordlist):\n",
    "    stem_words = []\n",
    "    for x in wordlist:\n",
    "        xtoken = x.strip().split()\n",
    "        xstem = [ps.stem(t) for t in xtoken]\n",
    "        if len(xstem)>1:\n",
    "            out = ' '.join(xstem)\n",
    "            stem_words.append(out)\n",
    "        elif len(xstem)==1:\n",
    "            out = xstem[0]\n",
    "            stem_words.append(xstem[0])\n",
    "        else:\n",
    "            stem_words.append('')\n",
    "\n",
    "    return stem_words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# action terms\n",
    "expect_keywords = [\n",
    "    'may becom','hope','outlook','go to','tailwind','work toward','trend','is like to','may depend','may not','forse','would','seek to','ought','potenti','could depend','unknown','remain confid','shortterm','depend','endeavor','intend','abl to remain','feel','may result','project','expect to','possibl','like will result','goal','may affect','go forward','belief','consid','estim will','contempl','suggest','pursu','call for','appear','well posit to','think','with a view to','appear to','up to','short term','prioriti','hypothes','can have','indic','may impact','schedul','envis','believ','could','look forward','pro forma','drive','uncertain','explor','could be','look forward to','see','prospect','upsid','may','should','is like','risk','improv','longterm','like','uncertainti','tent','forese','predict','would be','headwind','view','move toward','aim','estim','on target','pend','probabl','could potenti','might','may be','are like','pipelin','do not expect','may continu','seek','will','shall','not expect','will like result','futur','unanticip','guidanc','look ahead','likelihood','like to','full year guidanc','anticip','confid','opportun','propos','on pace','plan','schedul to','preliminari','will like','will like be','do not anticip','expect','presum','express confid','can be','opportunity','plans','believes','could potentially','is likely to','drive','predicting','may affect','may continue','uncertain','expect','headwind','would be','shall','depend','expressed confidence','projects','aims','looking forward','scheduled to','think','hopefully','on target','presume','seek to','view','looks forward','expects','belief','pending','may not','suggests','moving toward','depends','believe','goals','trend','do not expect','appear to'\n",
    "]\n",
    "\n",
    "amendment_keywords = \\\n",
    "[\n",
    "    'amend', 'modif', 'renegotiate', 'forbearance', 'waiv', 'in default', 'viol', \n",
    "    'not in compliance'\n",
    "]\n",
    "\n",
    "increase_keywords = \\\n",
    "[\n",
    "    'increase', 'raise', 'upward'\n",
    "]\n",
    "\n",
    "decrease_keywords = \\\n",
    "[\n",
    "    'decrease', 'reduce', 'lower', 'downward'\n",
    "]\n",
    "\n",
    "terminate_keywords = \\\n",
    "[\n",
    "    'terminate', 'suspend', 'cancel', 'paid in full'\n",
    "]\n",
    "\n",
    "require_keywords = \\\n",
    "[\n",
    "    'require', 'pledge', 'add', 'provide', 'deposit'\n",
    "]\n",
    "\n",
    "adjust_keywords = \\\n",
    "[\n",
    "    'adjust', 'change', 'update', 'decrease', 'lower', 'reduce', 'shorten'\n",
    "]\n",
    "\n",
    "# loan terms\n",
    "loan_keywords = \\\n",
    "[\n",
    "    'covenant', 'line of credit', 'lines of credit', 'credit line',\n",
    "    'credit facility', 'loan facility', 'revolving facility', \n",
    "    'credit agreement', 'loan agreement', 'financing agreement',\n",
    "    'revolving credit', 'revolver', 'term loan'\n",
    "]\n",
    "\n",
    "\n",
    "rate_keywords = \\\n",
    "[\n",
    "    'interest rate', 'rate', 'yield', 'spread', 'margin',\n",
    "    'borrowing cost','pricing grid','commitment fee',\n",
    "    'rate increment', 'libor increment'\n",
    "]\n",
    "\n",
    "amount_keywords = \\\n",
    "[\n",
    "    'amount', 'size', 'commitment', 'capacity', 'limit', 'sublimit', 'committed',\n",
    "    'line of credit', 'lines of credit', 'lines of credit', 'credit line', 'revolving credit', 'revolver', \n",
    "    'loan facility', 'credit facility', 'revolving facility',\n",
    "    'borrowing base', 'maximum available', 'credit availability', 'available credit'\n",
    "]\n",
    "\n",
    "maturity_keywords = \\\n",
    "[\n",
    "    'matur'\n",
    "]\n",
    "\n",
    "collateral_keywords = \\\n",
    "[\n",
    "    'collateral'\n",
    "]\n",
    "\n",
    "# misc \n",
    "exclude_keywords = \\\n",
    "[\n",
    "    'adjustable rate', 'gross margin', 'borrowing condition', 'floating rate',\n",
    "    'adjusted eurodollar rate', 'adjusted libor rate', 'exchange rate', 'adjustable margin',\n",
    "    'adjusted libor'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data cleaning. return tokens\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "\n",
    "    # remove formatting\n",
    "    sentence = re.sub('\\n',' ', sentence) # remove line break markers \n",
    "    sentence = re.sub('&#[0-9]+;',' ', sentence) # remove character ids\n",
    "    \n",
    "    # remove months etc\n",
    "    sentence = re.sub('covenant skills','', sentence)\n",
    "    sentence = re.sub('customer covenant','', sentence)\n",
    "    \n",
    "    # remove capitalization, punctuations (dont remove numbers, dollar signs, full stops, commas)\n",
    "    sentence = re.sub(\"[^A-Za-z0-9$.,\\s]\",' ',sentence) \n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower() \n",
    "    \n",
    "    # additional cleaning\n",
    "    sentence = re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', sentence)\n",
    "    sentence = re.sub(r'(mda|md a)','', sentence) # short form\n",
    "    sentence = re.sub(r'form\\s\\w{0,1}','',sentence) # form number\n",
    "    sentence = re.sub('table of contents','',sentence) # table of contents\n",
    "    sentence = re.sub(r'(item|i tem)\\s{0,1}[0-9]*[a-z]{0,1}','', sentence) # header\n",
    "    sentence = re.sub('(year|years) ended','', sentence)\n",
    "    sentence = re.sub('page\\s{0,1}[0-9]*','',sentence)\n",
    "    sentence = re.sub('rsquo','', sentence)\n",
    "    sentence = re.sub('amp','', sentence)\n",
    "    sentence = re.sub('rdquo','',sentence)\n",
    "    sentence = re.sub('ldquo','',sentence)\n",
    "    \n",
    "    # remove hanging characters\n",
    "    sentence = re.sub(r'\\b[b-z]\\b',' ', sentence) # remove hanging characters\n",
    "    sentence = re.sub(r'(?<!\\w)\\.(?!\\w)',' ',sentence) # remove hanging .\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify dates from sentence and indicate whether it is one year before filing date\n",
    "\n",
    "def catch(func, handle=lambda e : e, *args, **kwargs):\n",
    "    try:\n",
    "        return func(*args, **kwargs)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def find_olddate(sent,filing_date):\n",
    "    \n",
    "    any_olddate = 0\n",
    "\n",
    "    filing_date = datetime.strptime(filing_date,\"%Y-%m-%d\")\n",
    "    prevdate = filing_date-relativedelta(months=6) # filing date up to 2 months after end of quarter\n",
    "    \n",
    "    # date (e.g. jan 31, 2021)\n",
    "    regex = r'\\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s(?:\\d{1,2},)\\s(?:19[7-9]\\d|2\\d{3})(?=\\D|$)'\n",
    "    datestr = re.findall(regex,sent)\n",
    "    datefmt0 = [catch(lambda : datetime.strptime(s, '%B %d, %Y')) for s in datestr]\n",
    "    \n",
    "    regex = re.compile('|'.join(datestr)) # remove pattern from sentence (so don't double parse)\n",
    "    sent = re.sub(regex, '',sent)\n",
    "    \n",
    "    # date format (e.g. jan 2021)\n",
    "    regex = r'\\b(?:january|february|march|april|may|june|july|august|september|october|november|december)\\s(?:19[7-9]\\d|2\\d{3})(?=\\D|$)'\n",
    "    datestr = re.findall(regex,sent)\n",
    "    datefmt1 = [catch(lambda : datetime.strptime(s, '%B %Y')) for s in datestr]\n",
    "    \n",
    "    regex = re.compile('|'.join(datestr)) # remove pattern from sentence (so don't double parse)\n",
    "    sent = re.sub(regex, '',sent)\n",
    "    \n",
    "    # date format (e.g. 2021) - assume refers to midyear month\n",
    "    regex = r'(?:(?<=\\D))(?:19[7-9]\\d|2[0-1]\\d{2})(?=\\D|$)'\n",
    "    datestr = re.findall(regex,sent)\n",
    "    datefmt2 = [catch(lambda : datetime.strptime(s, '%Y')+relativedelta(months=6)) for s in datestr]\n",
    "\n",
    "    # combine all parsed dates\n",
    "    datefmt = datefmt0 + datefmt1 + datefmt2\n",
    "    datefmt = [d for d in datefmt if d is not None]\n",
    "\n",
    "    olddate = 0\n",
    "    if len(datefmt) >0:\n",
    "        olddate = np.mean([1 if (d is not None) and (d < prevdate) else 0 for d in datefmt])\n",
    "    \n",
    "    any_olddate = 0\n",
    "    if olddate >= 0.5:\n",
    "        any_olddate = 1\n",
    "    \n",
    "    return any_olddate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sentences around covenant mentions / loan agreement amendments etc\n",
    "def parse_text(sentences, filing_date):\n",
    "    \n",
    "    # use dataframe structure\n",
    "    df = pd.DataFrame(columns = ['row','text'])\n",
    "    df['rawtext'] = sentences\n",
    "    df['row'] = df.index\n",
    "        \n",
    "    # delete misleading terms\n",
    "    regex = r'\\b(?:' + '|'.join(exclude_keywords) + r')'\n",
    "    df['text'] = df['rawtext'].apply(lambda x: re.sub(regex, '', x))\n",
    "\n",
    "    # query loan keywords\n",
    "    regex = r'\\b(?:' + '|'.join(loan_keywords) + r')'\n",
    "    df['query_loan'] = df['text'].apply(lambda x: int(len(re.findall(regex,x))>0))\n",
    "\n",
    "    # query amendment keywords\n",
    "    regex = r'\\b(?:' + '|'.join(amendment_keywords) + r')'\n",
    "    df['query_amend'] = df['text'].apply(lambda x: int(len(re.findall(regex,x))>0))\n",
    "    \n",
    "    # query expect keywords\n",
    "    regex = r'\\b(?:' + '|'.join(expect_keywords) + r')'\n",
    "    df['query_expect'] = df['text'].apply(lambda x: int(len(re.findall(regex,x))>0))\n",
    "    \n",
    "    # search for year in amendment sentence\n",
    "    df['query_olddate'] = df['text'].apply(lambda x: find_olddate(x,filing_date))\n",
    "\n",
    "    # query interest rate keywords\n",
    "    regex = r'\\b(?:'+'|'.join(increase_keywords)+r')[A-z0-9\\s]{0,30}\\b(?:'+ '|'.join(rate_keywords) + r')' \\\n",
    "        + r'|\\b(?:' + '|'.join(rate_keywords) + r')[A-z0-9\\s]{0,30}\\b(?:(?:was|were)\\s{0,1}(?:' + '|'.join(increase_keywords) + r'))'\n",
    "    df['word_rate'] = df['text'].apply(lambda x: re.findall(regex,x))\n",
    "    df['query_rate'] = df['word_rate'].apply(lambda x: int(len(x)>0))\n",
    "\n",
    "    # query borrowing changes keywords\n",
    "    regex = r'\\b(?:'+'|'.join(decrease_keywords)+r')[A-z0-9\\s]{0,30}\\b(?:'+ '|'.join(amount_keywords) + r')(?:(?!\\srate|\\sfee|\\scondition))' \\\n",
    "        + r'|\\b(?:' + '|'.join(amount_keywords) + r')[A-z0-9\\s]{0,30}\\b(?:(?:was|were)\\s{0,1}(?:' + '|'.join(decrease_keywords) + r'))'\n",
    "    df['word_amount'] = df['text'].apply(lambda x: re.findall(regex,x))\n",
    "    df['query_amount'] = df['word_amount'].apply(lambda x: int(len(x)>0))\n",
    "\n",
    "    # query terminate agreement keywords\n",
    "    regex = r'\\b(?:'+'|'.join(terminate_keywords)+r')[A-z0-9\\s]{0,30}\\b(?:'+ '|'.join(loan_keywords) + r')' \\\n",
    "        + r'|\\b(?:' + '|'.join(loan_keywords) + r')[A-z0-9\\s]{0,30}\\b(?:(?:was|were)\\s{0,1}(?:' + '|'.join(terminate_keywords) + r'))'\n",
    "    df['word_terminate'] = df['text'].apply(lambda x: re.findall(regex,x))\n",
    "    df['query_terminate'] = df['word_terminate'].apply(lambda x: int(len(x)>0))  \n",
    "    \n",
    "    # query reduce maturity keywords\n",
    "    regex = r'\\b(?:'+'|'.join(adjust_keywords)+r')[A-z0-9\\s]{0,30}\\b(?:'+ '|'.join(maturity_keywords) + r')' \\\n",
    "        + r'|\\b(?:' + '|'.join(maturity_keywords) + r')[A-z0-9\\s]{0,30}\\b(?:(?:was|were)\\s{0,1}(?:' + '|'.join(adjust_keywords) + r'))'\n",
    "    df['word_maturity'] = df['text'].apply(lambda x: re.findall(regex,x))\n",
    "    df['query_maturity'] = df['word_maturity'].apply(lambda x: int(len(x)>0))  \n",
    "    \n",
    "    # query additional collateral keywords\n",
    "    regex = r'\\b(?:'+'|'.join(require_keywords)+r')[A-z0-9\\s]{0,30}\\b(?:'+ '|'.join(collateral_keywords) + r')' \\\n",
    "        + r'|\\b(?:' + '|'.join(collateral_keywords) + r')[A-z0-9\\s]{0,30}\\b(?:(?:was|were)\\s{0,1}(?:' + '|'.join(require_keywords) + r'))'\n",
    "    df['word_collateral'] = df['text'].apply(lambda x: re.findall(regex,x))\n",
    "    df['query_collateral'] = df['word_collateral'].apply(lambda x: int(len(x)>0))  \n",
    "\n",
    "    # check if mentions corresponds to correct date range\n",
    "    mask = (df.query_olddate>0)|(df.query_loan==0)|(df.query_expect>0)\n",
    "    df.loc[mask,'query_amend'] = 0\n",
    "\n",
    "    mask = (df.query_olddate>0)|(df.query_expect>0)\n",
    "    df.loc[mask,'query_rate'] = 0\n",
    "    df.loc[mask,'query_amount'] = 0\n",
    "    df.loc[mask,'query_terminate'] = 0\n",
    "    df.loc[mask,'query_maturity'] = 0\n",
    "    df.loc[mask,'query_collateral'] = 0\n",
    "\n",
    "    # get relevant text (up to 2 sentences following valid amendment)\n",
    "    df['l1'] = df.query_amend.shift(1)\n",
    "    df['l2'] = df.query_amend.shift(2)\n",
    "    df['l3'] = df.query_amend.shift(3)\n",
    "    df['_all'] = df[['query_amend','l1','l2','l3']].sum(axis=1)    \n",
    "\n",
    "    # save output\n",
    "    out = {}\n",
    "    amend_full_text = None\n",
    "    amend_rate_text = None\n",
    "    amend_amount_text = None\n",
    "    amend_terminate_text = None\n",
    "    amend_maturity_text = None\n",
    "    amend_collateral_text = None\n",
    "    amend_rate_keyword = None\n",
    "    amend_amount_keyword = None\n",
    "    amend_terminate_keyword = None\n",
    "    amend_maturity_keyword = None\n",
    "    amend_collateral_keyword = None\n",
    "    amend_rate_ind = 0\n",
    "    amend_amount_ind = 0\n",
    "    amend_terminate_ind = 0\n",
    "    amend_maturity_ind = 0\n",
    "    amend_collateral_ind = 0\n",
    "\n",
    "    if df._all.sum()>0:\n",
    "\n",
    "        df = df[df._all>0]\n",
    "        amend_full_text = ' '.join(list(df['rawtext'].values))\n",
    "\n",
    "        if df.query_rate.sum()>0:\n",
    "            amend_rate_text = df.loc[df.query_rate>0,'rawtext'].sum()\n",
    "            amend_rate_keyword = df.loc[df.query_rate>0,'word_rate'].sum()\n",
    "            amend_rate_ind = 1\n",
    "\n",
    "        if df.query_amount.sum()>0:\n",
    "            amend_amount_text = df.loc[df.query_amount>0,'rawtext'].sum()\n",
    "            amend_amount_keyword = df.loc[df.query_amount>0,'word_amount'].sum()\n",
    "            amend_amount_ind = 1\n",
    "\n",
    "        if df.query_terminate.sum()>0:\n",
    "            amend_terminate_text = df.loc[df.query_terminate>0,'rawtext'].sum()\n",
    "            amend_terminate_keyword = df.loc[df.query_terminate>0,'word_terminate'].sum()\n",
    "            amend_terminate_ind = 1\n",
    "            \n",
    "        if df.query_maturity.sum()>0:\n",
    "            amend_maturity_text = df.loc[df.query_maturity>0,'rawtext'].sum()\n",
    "            amend_maturity_keyword = df.loc[df.query_maturity>0,'word_maturity'].sum()\n",
    "            amend_maturity_ind = 1\n",
    "\n",
    "        if df.query_collateral.sum()>0:\n",
    "            amend_collateral_text = df.loc[df.query_collateral>0,'rawtext'].sum()\n",
    "            amend_collateral_keyword = df.loc[df.query_collateral>0,'word_collateral'].sum()\n",
    "            amend_collateral_ind = 1            \n",
    "        \n",
    "    # save output\n",
    "    out['amend_full_text'] = amend_full_text\n",
    "    \n",
    "    out['amend_rate_text'] = amend_rate_text\n",
    "    out['amend_rate_keyword'] = amend_rate_keyword\n",
    "    out['amend_rate_ind'] = amend_rate_ind\n",
    "    \n",
    "    out['amend_amount_text'] = amend_amount_text\n",
    "    out['amend_amount_keyword'] = amend_amount_keyword\n",
    "    out['amend_amount_ind'] = amend_amount_ind    \n",
    "    \n",
    "    out['amend_terminate_text'] = amend_terminate_text\n",
    "    out['amend_terminate_keyword'] = amend_terminate_keyword\n",
    "    out['amend_terminate_ind'] = amend_terminate_ind\n",
    "\n",
    "    out['amend_maturity_text'] = amend_maturity_text\n",
    "    out['amend_maturity_keyword'] = amend_maturity_keyword\n",
    "    out['amend_maturity_ind'] = amend_maturity_ind\n",
    "    \n",
    "    out['amend_collateral_text'] = amend_collateral_text\n",
    "    out['amend_collateral_keyword'] = amend_collateral_keyword\n",
    "    out['amend_collateral_ind'] = amend_collateral_ind\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get raw text from input filepath\n",
    "\n",
    "def read_text(file, header=8):\n",
    "    \n",
    "    # get text\n",
    "    s3_client = boto3.client('s3')\n",
    "    obj = s3_client.get_object(Bucket=bucket,Key=file)\n",
    "    raw_text = obj['Body'].read().decode('utf-8').splitlines()\n",
    "        \n",
    "    # get file info\n",
    "    master_idx = re.search(r'(?<=<master idx>)(.*?)(?=</master idx>)', raw_text[0]).group(0)\n",
    "    cik = re.search(r'(?<=<cik>)(.*?)(?=</cik>)', raw_text[1]).group(0)\n",
    "    company_name = re.search(r'(?<=<company name>)(.*?)(?=</company name>)', raw_text[2]).group(0)\n",
    "    filing_type = re.search(r'(?<=<filing type>)(.*?)(?=</filing type>)', raw_text[3]).group(0)\n",
    "    filing_date = re.search(r'(?<=<filing date>)(.*?)(?=</filing date>)', raw_text[4]).group(0)\n",
    "    report_date = re.search(r'(?<=<report date>)(.*?)(?=</report date>)', raw_text[5]).group(0)\n",
    "    \n",
    "    # filter for incorrect text (old text mixed in)\n",
    "    valid_flag = 1\n",
    "    if len(raw_text)>=10:\n",
    "        incorrect_text = re.search(r'(^Our operating results may fluctuate significantly)',raw_text[9])\n",
    "        if incorrect_text:\n",
    "            valid_flag = 0\n",
    "    \n",
    "    # body of text\n",
    "    body = raw_text[header:] # remove header lines\n",
    "    \n",
    "    # join to single string\n",
    "    body = ' '.join(body) \n",
    "\n",
    "    # split into sentences\n",
    "    body = re.sub(r'(?<=No)\\.(?!\\w)', '',body) # dont tokenize \"No. 1\"\n",
    "    sentences = sent_tokenize(body)\n",
    "    \n",
    "    # clean sentence\n",
    "    sentences_clean = [clean_sentence(s) for s in sentences] # clean and tokenize\n",
    "    sentences_clean = [s for s in sentences_clean if len(s) > 1]\n",
    "    \n",
    "    # parse text\n",
    "    query = parse_text(sentences_clean, filing_date = filing_date)\n",
    "\n",
    "    return {\n",
    "        'master_idx': master_idx,\n",
    "        'cik': cik,\n",
    "        'company_name': company_name,\n",
    "        'filing_type': filing_type,\n",
    "        'filing_date': filing_date,\n",
    "        'valid_text': valid_flag,\n",
    "        'amend_full_text': query['amend_full_text'],\n",
    "        'amend_rate_text': query['amend_rate_text'],\n",
    "        'amend_rate_keyword': query['amend_rate_keyword'],        \n",
    "        'amend_rate_ind': query['amend_rate_ind'],\n",
    "        'amend_amount_keyword': query['amend_amount_keyword'],\n",
    "        'amend_amount_text': query['amend_amount_text'],\n",
    "        'amend_amount_ind': query['amend_amount_ind'],\n",
    "        'amend_terminate_text': query['amend_terminate_text'],\n",
    "        'amend_terminate_keyword': query['amend_terminate_keyword'],\n",
    "        'amend_terminate_ind': query['amend_terminate_ind'],\n",
    "        'amend_maturity_text': query['amend_maturity_text'],\n",
    "        'amend_maturity_keyword': query['amend_maturity_keyword'],\n",
    "        'amend_maturity_ind': query['amend_maturity_ind'],\n",
    "        'amend_collateral_text': query['amend_collateral_text'],\n",
    "        'amend_collateral_keyword': query['amend_collateral_keyword'],\n",
    "        'amend_collateral_ind': query['amend_collateral_ind'],        \n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read file paths\n",
    "\n",
    "yearstart = int(input('start year: '))\n",
    "yearend = int(input('end year: '))\n",
    "yrlist = range(yearstart,yearend+1)\n",
    "qtrlist = range(1,5)\n",
    "\n",
    "for yr in reversed(yrlist):\n",
    "    \n",
    "    df_all = pd.DataFrame()\n",
    "    \n",
    "    for qtr in qtrlist:\n",
    "        \n",
    "        print(f'parsing text for year {yr} qtr {qtr} \\n')\n",
    "\n",
    "        prefix = f\"edgar_mda_new_2/{yr}/QTR{qtr}/\"\n",
    "        # prefix = f\"edgar_mda_new/test/\"\n",
    "        s3_client = boto3.client('s3')\n",
    "        paginator = s3_client.get_paginator('list_objects_v2')\n",
    "        pages = paginator.paginate(Bucket=bucket, Prefix=prefix)\n",
    "        filepath = [obj['Key'] for page in pages for obj in page['Contents'] if '.txt' in obj['Key']]\n",
    "\n",
    "        # get tokenized sentences and filing info (nested list: token -> sentence -> document)\n",
    "        df = Parallel(n_jobs=multiprocessing.cpu_count(), batch_size=32) \\\n",
    "                (delayed(read_text)(file, header=8) for file in tqdm(filepath)) \n",
    "        df = pd.DataFrame(df)\n",
    "        \n",
    "        df_all = df_all.append(df, ignore_index=True)\n",
    "        \n",
    "    output_prefix = f's3://{bucket}/edgar_mda_new_2_amendments/'\n",
    "    savepath = output_prefix + f'{yr}_amendments.gzip'\n",
    "    wr.s3.to_parquet(\n",
    "        df=df_all,\n",
    "        path=savepath,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract numerical indicators as stata input\n",
    "Note: the code above is run in python script (takes about 4 hours to run)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "yearstart = int(input('start year: '))\n",
    "yearend = int(input('end year: '))\n",
    "yearlist = range(yearstart,yearend+1)\n",
    "\n",
    "for yr in reversed(yearlist):\n",
    "        \n",
    "    print(f'reading file from year {yr} \\n')\n",
    "\n",
    "    # read file\n",
    "    s3_client = boto3.client('s3')\n",
    "    file = f\"edgar_mda_new_2_amendments/{yr}_amendments.gzip\"\n",
    "    obj = s3_client.get_object(Bucket=bucket,Key=file)\n",
    "    df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "    \n",
    "    # extract indicators\n",
    "    df = df[df.valid_text==1].reset_index(drop=True)\n",
    "    df_out = df[['master_idx',cik','company_name','filing_type','filing_date',\n",
    "                 'amend_rate_ind','amend_amount_ind','amend_terminate_ind','amend_maturity_ind','amend_collateral_ind']]  \n",
    "    df_out = df_out.fillna(0)\n",
    "    \n",
    "    df_all = df_all.append(df_out, ignore_index=True)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output to file\n",
    "output_prefix = f's3://{bucket}/output/'\n",
    "savepath = output_prefix +'edgar_mda_new_amendments_2_postsubmit.txt'\n",
    "wr.s3.to_csv(\n",
    "    df=df_all,\n",
    "    path=savepath,\n",
    "    sep='|'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
