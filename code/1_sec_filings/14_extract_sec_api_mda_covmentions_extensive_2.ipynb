{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21c84e28",
   "metadata": {},
   "source": [
    "Extract query_cov_fut from sec mda filings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601b20bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import multiprocessing\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "import spacy\n",
    "from spacy.language import Language\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import io\n",
    "\n",
    "ps = PorterStemmer()\n",
    "bucket = 'sagemaker-us-east-2-269018301143'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a6b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# incorporate expect keywords\n",
    "\n",
    "expect_keywords_all = [\n",
    "    'may becom','hope','outlook','go to','tailwind','work toward','trend','is like to','may depend','may not','forse','would','seek to','ought','potenti','could depend','unknown','remain confid','shortterm','depend','endeavor','intend','abl to remain','feel','may result','project','expect to','possibl','like will result','goal','may affect','go forward','belief','consid','estim will','contempl','suggest','pursu','call for','appear','well posit to','think','with a view to','appear to','up to','short term','prioriti','hypothes','can have','indic','may impact','schedul','envis','believ','could','look forward','pro forma','drive','uncertain','explor','could be','look forward to','see','prospect','upsid','may','should','is like','risk','improv','longterm','like','uncertainti','tent','forese','predict','would be','headwind','view','move toward','aim','estim','on target','pend','probabl','could potenti','might','may be','are like','pipelin','do not expect','may continu','seek','will','shall','not expect','will like result','futur','unanticip','guidanc','look ahead','likelihood','like to','full year guidanc','anticip','confid','opportun','propos','on pace','plan','schedul to','preliminari','will like','will like be','do not anticip','expect','presum','express confid','can be','opportunity','plans','believes','could potentially','is likely to','drive','predicting','may affect','may continue','uncertain','expect','headwind','would be','shall','depend','expressed confidence','projects','aims','looking forward','scheduled to','think','hopefully','on target','presume','seek to','view','looks forward','expects','belief','pending','may not','suggests','moving toward','depends','believe','goals','trend','do not expect','appear to'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6015bb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data cleaning. return tokens\n",
    "\n",
    "def clean_sentence(sentence):\n",
    "\n",
    "    # remove formatting\n",
    "    sentence = re.sub('\\n',' ', sentence) # remove line break markers \n",
    "    sentence = re.sub('&#[0-9]+;',' ', sentence) # remove character ids\n",
    "    \n",
    "    # remove months etc\n",
    "    sentence = re.sub('covenant skills','', sentence)\n",
    "    sentence = re.sub('customer covenant','', sentence)\n",
    "    sentence = re.sub(r\"\\b(?:'ll|we'll|will|may|should|shouldn't|can|can't|would|wouldn't|can also|may also|will also|should also) \\b(?:increase|decrease|step down|step up|see|say|mention|recall|note|add|talk|like to)\",'', sentence)\n",
    "    sentence = re.sub('May','',sentence)\n",
    "    \n",
    "    # remove capitalization, punctuations (dont remove numbers, dollar signs, full stops, commas)\n",
    "    sentence = re.sub(\"[^A-Za-z0-9$.,\\s]\",' ',sentence) \n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower() \n",
    "    \n",
    "    # additional cleaning\n",
    "    sentence = re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', sentence)\n",
    "    sentence = re.sub(r'(mda|md a)','', sentence) # short form\n",
    "    sentence = re.sub(r'form\\s\\w{0,1}','',sentence) # form number\n",
    "    sentence = re.sub('table of contents','',sentence) # table of contents\n",
    "    sentence = re.sub(r'(item|i tem)\\s{0,1}[0-9]*[a-z]{0,1}','', sentence) # header\n",
    "    sentence = re.sub('(year|years) ended','', sentence)\n",
    "    sentence = re.sub('page\\s{0,1}[0-9]*','',sentence)\n",
    "    sentence = re.sub('rsquo','', sentence)\n",
    "    sentence = re.sub('amp','', sentence)\n",
    "    sentence = re.sub('rdquo','',sentence)\n",
    "    sentence = re.sub('ldquo','',sentence)\n",
    "    \n",
    "    # remove hanging characters\n",
    "#     sentence = re.sub(r'\\b[b-hj-z]\\b',' ', sentence) # remove hanging characters\n",
    "    sentence = re.sub(r'(?<!\\w)\\.(?!\\w)',' ',sentence) # remove hanging .\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9b2539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to get covfuture indicators\n",
    "# input: text as string\n",
    "# output: dictionary of relevant indicators\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# ADD A NEW RULE TO THE PIPELINE\n",
    "subsentence_id = [\",\",\".\",\"!\",\"?\",\";\",\n",
    "                  \"or\",\"after\",\"because\",\"but\",\n",
    "                  \"so\", \"when\", \"where\", \"while\", \n",
    "                  \"although\", \"however\", \"though\", \"whereas\"\n",
    "                  \"so that\", \"despite\"]\n",
    "\n",
    "@Language.component(\"set_custom_boundaries\")\n",
    "def set_custom_boundaries(doc):\n",
    "    for token in doc[:-1]:\n",
    "        if token.text in subsentence_id:\n",
    "            doc[token.i + 1].is_sent_start = True\n",
    "    return doc\n",
    "\n",
    "nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n",
    "\n",
    "def parse_text(text):\n",
    "    \"\"\"\n",
    "    :param text: A string of text to parse.\n",
    "    :return: A dictionary (out1) with aggregated numeric indicators:\n",
    "             - query_covenant, query_cov_past, query_cov_act, query_cov_fut, etc.\n",
    "             - word_count, expect_count, total_words_in_document\n",
    "             - fut_sentences_word_count, fut_sentences_expect_count\n",
    "             ... and any other sums from the sentence-level results.\n",
    "    \"\"\"\n",
    "    # Prepare the final aggregated output\n",
    "    out1 = dict()\n",
    "\n",
    "    # Only parse if text is a string\n",
    "    if isinstance(text, str) and text.strip():\n",
    "        # 1) Parse using spaCy\n",
    "        doc_parse = nlp(text.strip())\n",
    "        \n",
    "        out = []  # Will store sentence-level dictionaries\n",
    "\n",
    "        # 2) Iterate over each sentence\n",
    "        for i_sent, sent in enumerate(doc_parse.sents):\n",
    "            # Word count (ignore punctuation and whitespace)\n",
    "            word_count = sum(1 for token in sent if not token.is_punct and not token.is_space)\n",
    "\n",
    "            # Flag past tense\n",
    "            past_flag = 0\n",
    "            if (sent.root.tag_ in [\"VBD\", \"VBN\"]) or any(\n",
    "               (w.dep_ in [\"aux\",\"auxpass\"]) and (w.tag_ in [\"VBD\",\"VBN\"])\n",
    "               for w in sent.root.children\n",
    "            ):\n",
    "                past_flag = 1\n",
    "\n",
    "            # Flag present tense\n",
    "            present_flag = 0\n",
    "            present_tag = [\"VB\",\"VBG\",\"VBP\",\"VBZ\"]\n",
    "            nonpresent_tag = [\"VBD\",\"VBN\",\"MD\"]\n",
    "            if (sent.root.tag_ in present_tag) and not any(\n",
    "               (w.dep_ in [\"aux\",\"auxpass\"]) and (w.tag_ in nonpresent_tag)\n",
    "               for w in sent.root.children\n",
    "            ):\n",
    "                present_flag = 1\n",
    "\n",
    "            # Flag future tense\n",
    "            future_flag = 0\n",
    "            if (sent.root.tag_ in present_tag) and any(\n",
    "               (w.dep_ in [\"aux\",\"auxpass\"]) and (w.tag_ == \"MD\")\n",
    "               for w in sent.root.children\n",
    "            ):\n",
    "                future_flag = 1\n",
    "\n",
    "            # Flag covenant keywords\n",
    "            regex = r'\\b(?:covenant|convenant)'\n",
    "            covenant = re.findall(regex, sent.text)\n",
    "            covenant_flag = int(len(covenant) > 0)\n",
    "\n",
    "            # Flag expectation keywords\n",
    "            expect_regex = r'\\b(' + '|'.join(expect_keywords_all) + r')'\n",
    "            expect = re.findall(expect_regex, sent.text)\n",
    "            expect_count = len(expect)\n",
    "            expect_flag = int(expect_count > 0)\n",
    "\n",
    "            # covmention labels\n",
    "            query_cov_fut = 0\n",
    "            query_cov_act = 0\n",
    "            query_cov_past = 0\n",
    "            query_cov_fut_tense = 0\n",
    "\n",
    "            if (covenant_flag == 1) and (past_flag == 1):\n",
    "                if expect_flag == 0:\n",
    "                    query_cov_past = 1\n",
    "\n",
    "            elif (covenant_flag == 1) and (present_flag == 1):\n",
    "                if expect_flag == 1:\n",
    "                    query_cov_fut = 1\n",
    "                else:\n",
    "                    query_cov_act = 1\n",
    "\n",
    "            elif (covenant_flag == 1) and (future_flag == 1):\n",
    "                query_cov_fut = 1\n",
    "                query_cov_fut_tense = 1\n",
    "\n",
    "            else:\n",
    "                if (covenant_flag == 1) and (expect_flag == 1):\n",
    "                    query_cov_fut = 1\n",
    "\n",
    "            # Sub-lists for each category\n",
    "            expect_keywords = []\n",
    "            covmentions_fut = []\n",
    "            covmentions_past = []\n",
    "            covmentions_act = []\n",
    "\n",
    "            if query_cov_fut == 1:\n",
    "                expect_keywords += expect\n",
    "                covmentions_fut.append(sent.text)\n",
    "\n",
    "            if query_cov_act == 1:\n",
    "                covmentions_act.append(sent.text)\n",
    "\n",
    "            if query_cov_past == 1:\n",
    "                covmentions_past.append(sent.text)\n",
    "\n",
    "            out.append({\n",
    "                \"query_covenant\": covenant_flag,\n",
    "                \"query_cov_past\": query_cov_past,\n",
    "                \"query_cov_act\": query_cov_act,\n",
    "                \"query_cov_fut\": query_cov_fut,\n",
    "                \"query_cov_fut_tense\": query_cov_fut_tense,\n",
    "                \"expect_keywords\": expect_keywords,\n",
    "                \"covmentions_fut\": covmentions_fut,\n",
    "                \"covmentions_past\": covmentions_past,\n",
    "                \"covmentions_act\": covmentions_act,\n",
    "                \n",
    "                # NEW columns\n",
    "                \"word_count\": word_count,\n",
    "                \"expect_count\": expect_count\n",
    "            })\n",
    "\n",
    "        # 3) Convert to DataFrame\n",
    "        out_df = pd.DataFrame(out)\n",
    "\n",
    "        # 4) If out_df is empty, return zeros\n",
    "        if out_df.empty:\n",
    "            out1 = {\n",
    "                \"query_covenant\": 0,\n",
    "                \"query_cov_past\": 0,\n",
    "                \"query_cov_act\": 0,\n",
    "                \"query_cov_fut\": 0,\n",
    "                \"query_cov_fut_tense\": 0,\n",
    "                \"word_count\": 0,\n",
    "                \"expect_count\": 0,\n",
    "                # Additional sums\n",
    "                \"fut_sentences_word_count\": 0,\n",
    "                \"fut_sentences_expect_count\": 0\n",
    "            }\n",
    "        else:\n",
    "            # 5) Summation of numeric columns\n",
    "            out1 = out_df.sum().to_dict()\n",
    "\n",
    "            # 6) Compute \"future-sentences\" subset\n",
    "            future_df = out_df[out_df[\"query_cov_fut\"] == 1]\n",
    "            out1[\"fut_sentences_word_count\"] = future_df[\"word_count\"].sum() if not future_df.empty else 0\n",
    "            out1[\"fut_sentences_expect_count\"] = future_df[\"expect_count\"].sum() if not future_df.empty else 0\n",
    "\n",
    "            # # 7) Total words in the document\n",
    "            # out1[\"total_words_in_document\"] = out_df[\"word_count\"].sum()\n",
    "    else:\n",
    "        # If it's not a string or it's empty, return zeros\n",
    "        out1 = {\n",
    "            \"query_covenant\": 0,\n",
    "            \"query_cov_past\": 0,\n",
    "            \"query_cov_act\": 0,\n",
    "            \"query_cov_fut\": 0,\n",
    "            \"query_cov_fut_tense\": 0,\n",
    "            \"word_count\": 0,\n",
    "            \"expect_count\": 0,\n",
    "            \"fut_sentences_word_count\": 0,\n",
    "            \"fut_sentences_expect_count\": 0\n",
    "        }\n",
    "\n",
    "    return out1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edce7d7c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# main program starts here\n",
    "\n",
    "df_all = pd.DataFrame()\n",
    "yrlist = range(2001,2022)\n",
    "# yrlist = [2020]\n",
    "for yr in yrlist:\n",
    "\n",
    "    print(f'parsing text for year {yr}  \\n')\n",
    "    \n",
    "    # read file\n",
    "    s3_client = boto3.client('s3')\n",
    "    file = f\"edgar_mda_new_2_covmentions_june2024/{yr}_covmentions.gzip\"\n",
    "    obj = s3_client.get_object(Bucket=bucket,Key=file)\n",
    "    df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    # search for keywords\n",
    "    print('finding forward-looking sentences...')\n",
    "    \n",
    "    query = Parallel(n_jobs=multiprocessing.cpu_count(), batch_size=32) \\\n",
    "            (delayed(parse_text)(text) for text in tqdm(df['cov_full_text'])) \n",
    "    query = pd.DataFrame(query)    \n",
    "    \n",
    "    # join\n",
    "    df1 = df.join(query)\n",
    "    df_all = df_all.append(df1, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a44d8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output \n",
    "# df_out = df_all[['master_idx','cik','company_name','filing_type','filing_date','report_date','query_covenant','query_cov_fut']]  \n",
    "df_out = df_all[['master_idx','cik','company_name','filing_type','filing_date','report_date','query_covenant','query_cov_fut','query_cov_act','query_cov_past','query_cov_fut_tense','fut_sentences_word_count','fut_sentences_expect_count','word_count']]  \n",
    "df_out = df_out.fillna(0)\n",
    "\n",
    "df_out.rename({'query_covenant': 'query_cov_sec', 'query_cov_fut':'query_covfut_sec','query_cov_act':'query_cov_act_sec','query_cov_past':'query_cov_past_sec',\n",
    "               'query_cov_fut_tense':'query_cov_fut_tense_sec','fut_sentences_word_count':'query_cov_fut_wc',\n",
    "               'fut_sentences_expect_count':'query_expect_wc','word_count':'query_covenant_wc'\n",
    "               }, axis=1, inplace=True)\n",
    "    \n",
    "output_prefix = f's3://{bucket}/output/'\n",
    "savepath = output_prefix +'sec_api_mda_covenant_mentions_june2024_update.txt'\n",
    "wr.s3.to_csv(\n",
    "    df=df_out,\n",
    "    path=savepath,\n",
    "    sep='|'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
