{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracts relevant variables from Dealscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new dataset \n",
    "\n",
    "dat_df = joblib.load('../../rawdata/dealscan/dealscan_new.pkl')\n",
    "\n",
    "dat_df.set_index(['lpc_tranche_id','tranche_active_date'], inplace=True)\n",
    "dat_df.sort_index(inplace=True)\n",
    "dat_df.reset_index(inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dat_df.columns:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep relevant variables\n",
    "\n",
    "dat_df_1 = dat_df[['borrower_id','lpc_deal_id','lpc_tranche_id','deal_active_date',\n",
    "                    'deal_currency','deal_amended','deal_amount','tranche_amount',\n",
    "                    'tranche_active_date','tranche_maturity_date','market_segment','tranche_type',\n",
    "                    'covenants', 'all_covenants_financial','deal_active','deal_refinancing',\n",
    "                    'base_reference_rate','all_in_spread_drawn_bps','all_in_spread_undrawn_bps'\n",
    "                  ]]\n",
    "dat_df_1['covenants'] = dat_df_1['covenants'].map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same tranche gets repeated for different lenders, so just keep unique \n",
    "\n",
    "dat_df_1 = dat_df_1\\\n",
    "    .groupby(['lpc_tranche_id','tranche_active_date']).first()\n",
    "dat_df_1.reset_index(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('max_rows',20)\n",
    "pd.set_option('max_colwidth',None)\n",
    "dat_df_1.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_covenants(str_in):\n",
    "    \n",
    "    out = dict()\n",
    "    \n",
    "    str_in = np.nan_to_num(str_in, nan=-99)\n",
    "    \n",
    "    if str_in and str_in != -99:\n",
    "        \n",
    "        variable = re.findall(r'[A-z\\s.]*.(?=:)', str_in)\n",
    "        value = re.findall(r'(?:(?<=to )|(?<=: )|(?<=is ))[-+]?[0-9]*\\.?[0-9]+(?:[eE][-+]?[0-9]+)?', str_in)\n",
    "        \n",
    "        out = dict([(i[0].strip(),float(i[1])) for i in zip(variable, value)])\n",
    "        \n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_marketsegment(str_in):\n",
    "    \n",
    "    out = dict()\n",
    "    \n",
    "    str_in = np.nan_to_num(str_in, nan=-99)\n",
    "    \n",
    "    if str_in and str_in != -99:\n",
    "        \n",
    "        regex = re.compile('leverage',re.IGNORECASE)\n",
    "        leverage = int(len(re.findall(regex,str_in))>0)\n",
    "        \n",
    "        regex = re.compile('covenant lite', re.IGNORECASE)\n",
    "        covlite = int(len(re.findall(regex,str_in))>0)\n",
    "        \n",
    "        out = {'levloan': leverage, 'covlite': covlite}\n",
    "        \n",
    "    return out\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tranchetype(str_in):\n",
    "    \n",
    "    revolver = 0\n",
    "    \n",
    "    str_in = np.nan_to_num(str_in, nan=-99)\n",
    "    \n",
    "    if str_in and str_in != -99:\n",
    "        \n",
    "        regex = r'\\b(?:Revolver|364-Day Facility)'\n",
    "        revolver = int(len(re.findall(regex,str_in))>0)\n",
    "        \n",
    "    return revolver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract covenants from covenant_financials\n",
    "\n",
    "dictList = dat_df_1['all_covenants_financial'].progress_apply(read_covenants)\n",
    "dictList1 = pd.DataFrame.from_dict(list(dictList))\n",
    "\n",
    "dat_df_1 = dat_df_1.join(dictList1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mktseg = dat_df_1['market_segment'].progress_apply(read_marketsegment)\n",
    "mktseg = pd.DataFrame.from_dict(list(mktseg))\n",
    "dat_df_1 = dat_df_1.join(mktseg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_df_1['revolver'] = dat_df_1['tranche_type'].progress_apply(read_tranchetype)\n",
    "dat_df_1.loc[dat_df_1.revolver==1,'revolver_amount'] = dat_df_1.loc[dat_df_1.revolver==1,'tranche_amount']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if extraction procedure is successful\n",
    "# if successful, this should yield no rows\n",
    "# note: there are fields where covenants == 0 but all_covenants_financial is not empty\n",
    "\n",
    "tmp = dat_df_1.copy()\n",
    "tmp['parseflag'] = (tmp[dictList1.columns.values.tolist()].isna().sum(axis=1)!=len(dictList1.columns))\n",
    "tmp['parseflag'] = tmp['parseflag'].astype(int)\n",
    "\n",
    "# covenant indicator = 1 but text not successfully parsed\n",
    "tmp[(tmp.covenants==1)&(tmp.parseflag==0)&(tmp.all_covenants_financial.notnull())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get borrower id link \n",
    "id_df = joblib.load('../../rawdata/dealscan/lpc_loanconnector_company_id_map.pkl')\n",
    "id_df.rename({'loanconnector_company_id':'borrower_id'}, axis=1, inplace=True)\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chava roberts link table\n",
    "roberts_df = pd.read_excel(\"../../rawdata/dealscan/Dealscan-Compustat_Linking_Database.xlsx\", sheet_name='link_data')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep one identifer per borrower-facility start date\n",
    "roberts_df['year'] = roberts_df.facstartdate.dt.year\n",
    "roberts_df_1 = roberts_df[['bcoid','gvkey','facstartdate','fic']].drop_duplicates(subset=['bcoid','facstartdate'])\n",
    "roberts_df_1.rename({'bcoid': 'lpc_company_id','facstartdate':'tranche_active_date'}, axis=1, inplace=True)\n",
    "roberts_df_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## do the merging here\n",
    "\n",
    "dat_df_2 = dat_df_1.copy()\n",
    "\n",
    "# adjust data type\n",
    "dat_df_2['tranche_active_date'] = pd.to_datetime(dat_df_2['tranche_active_date'], errors='coerce')\n",
    "dat_df_2['tranche_maturity_date'] = pd.to_datetime(dat_df_2['tranche_maturity_date'], errors='coerce')\n",
    "dat_df_2['deal_active_date'] = pd.to_datetime(dat_df_2['deal_active_date'], errors='coerce')\n",
    "\n",
    "# merge with old company identifiers\n",
    "dat_df_2 = dat_df_2.merge(id_df, on='borrower_id', how='outer', indicator=True, validate='many_to_one')\n",
    "print(dat_df_2._merge.value_counts())\n",
    "dat_df_2 = dat_df_2[dat_df_2._merge=='both'].reset_index(drop=True)\n",
    "dat_df_2.drop(['_merge'],axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with chava-roberts link table\n",
    "\n",
    "dat_df_2['lpc_company_id'] = dat_df_2['lpc_company_id'].astype(int)\n",
    "dat_df_2 = dat_df_2.merge(roberts_df_1, on=['lpc_company_id','tranche_active_date'], how='left', indicator=True, validate='many_to_one')\n",
    "print(dat_df_2._merge.value_counts())\n",
    "print(dat_df_2.gvkey.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry forward gvkey values for those with previous match (assume no change)\n",
    "\n",
    "dat_df_2.set_index(['lpc_company_id','tranche_active_date'], inplace=True)\n",
    "dat_df_2.sort_index(inplace=True)\n",
    "dat_df_2['gvkey'] = dat_df_2['gvkey'].groupby(level=0).fillna(method='ffill')\n",
    "\n",
    "# carry backward gvkey values for those with future match \n",
    "dat_df_2['gvkey'] = dat_df_2['gvkey'].groupby(level=0).fillna(method='bfill')\n",
    "\n",
    "# formatting\n",
    "dat_df_2.reset_index(inplace=True)\n",
    "dat_df_2.drop(['_merge'],axis=1,inplace=True)\n",
    "\n",
    "dat_df_2.gvkey.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat_df_2.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save tranche level data to compute average spreads \n",
    "\n",
    "dat_df_2.drop(['all_covenants_financial','market_segment'],axis=1, inplace=True)\n",
    "dat_df_2.to_stata('../../rawdata/dealscan/dealscan_new_2.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collapse to package level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collapse to package level (covenants apply to all loans in package)\n",
    "\n",
    "dat_df_3 = dat_df_2.copy()\n",
    "\n",
    "# drop variables that are not meaningful at the deal level\n",
    "dat_df_3.drop(['tranche_amount','market_segment'], axis=1, inplace=True)\n",
    "\n",
    "# for each deal_id-tranche_active_date, covenant applies to earliest tranche and latest maturity date\n",
    "# see Chava and Roberts 2008 p.2092 (tranche_active_date keeps track of amendments to tranches)\n",
    "dat_df_3['max_deal_maturity_date'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['tranche_maturity_date'].transform('max')\n",
    "dat_df_3['min_deal_active_date'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['tranche_active_date'].transform('min')\n",
    "dat_df_3['revolver_deal'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['revolver'].transform('max')\n",
    "dat_df_3['revolver_amount_deal'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['revolver_amount'].transform('max')\n",
    "dat_df_3['levloan_deal'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['levloan'].transform('max')\n",
    "dat_df_3['covlite_deal'] = dat_df_3.groupby(['lpc_deal_id','tranche_active_date'])['covlite'].transform('max')\n",
    "dat_df_3.drop(['revolver','revolver_amount','levloan','covlite'], axis=1, inplace=True)\n",
    "\n",
    "dat_df_3 = dat_df_3\\\n",
    "    .groupby(['lpc_deal_id','tranche_active_date']).first()\n",
    "\n",
    "dat_df_3.reset_index(inplace=True)\n",
    "\n",
    "# share of matches after carry forward and carry back\n",
    "# 51 percent of loans with matched gvkey\n",
    "dat_df_3.gvkey.notnull().sum() / dat_df_3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace maturity date by amended loan's active date if loan is amended \n",
    "# check if new active date is before existing maturity date\n",
    "dat_df_3.set_index(['lpc_deal_id','tranche_active_date'], inplace=True)\n",
    "dat_df_3.sort_index(inplace=True)\n",
    "dat_df_3['adj_deal_maturity_date'] = dat_df_3.groupby(level=0)['min_deal_active_date'].shift(-1)\n",
    "\n",
    "# if no amendment, then just use existing deal maturity date\n",
    "mask = dat_df_3.adj_deal_maturity_date.isnull()\n",
    "dat_df_3.loc[mask,'adj_deal_maturity_date'] = dat_df_3.loc[mask,'max_deal_maturity_date']\n",
    "\n",
    "# check if amendment start date after existing deal maturity date. if yes, then use existing maturity date\n",
    "mask = dat_df_3.adj_deal_maturity_date > dat_df_3.max_deal_maturity_date\n",
    "dat_df_3.loc[mask,'adj_deal_maturity_date'] = dat_df_3.loc[mask,'max_deal_maturity_date']\n",
    "\n",
    "dat_df_3.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if there are unmatched values \n",
    "#   92 facilities in CR table with unmatched values\n",
    "#   30 facilities for US incorp firms in Chava-Roberts table unmatched (15 firms)\n",
    "\n",
    "list_ = dat_df_3[dat_df_3.gvkey.isna()==True].lpc_company_id.unique()\n",
    "\n",
    "aux = roberts_df[roberts_df.bcoid.isin(list_)]\n",
    "\n",
    "aux[aux.fic==\"USA\"].company.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_df_3[(dat_df_3.tranche_active_date.dt.year>=2010)&(dat_df_3.covenants==1)].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## convert to long format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert data to long format (for merging in stata)\n",
    "\n",
    "dat_df_4 = dat_df_3.copy()\n",
    "\n",
    "# cov list\n",
    "cov_list = ['Tangible Net Worth',\n",
    "            'Min. Interest Coverage Ratio', \n",
    "            'Min. Current Ratio',\n",
    "            'Max. Debt to Cash Flow', \n",
    "            'Net Worth',\n",
    "            'Max. Debt to Tangible Net Worth Ratio',\n",
    "            'Min. Debt Service Coverage Ratio', \n",
    "            'Min. Fixed Charge Coverage Ratio',\n",
    "            'Max. Sr. Debt to Cash Flow', \n",
    "            'Max. Leverage Ratio',\n",
    "            'Min. Cash Interest Coverage Ratio', \n",
    "            'Max. Debt to Equity Ratio',\n",
    "            'Max. Loan to Value Ratio']\n",
    "\n",
    "dat_df_4 = pd.melt(dat_df_4, id_vars=['lpc_deal_id','tranche_active_date'], value_vars=cov_list) \\\n",
    "            .sort_values(['lpc_deal_id','tranche_active_date'])\n",
    "\n",
    "# merge in remaining values\n",
    "tmp = dat_df_3[['lpc_company_id', \n",
    "                'tranche_active_date', \n",
    "                'borrower_id',\n",
    "                'lpc_deal_id', \n",
    "                'min_deal_active_date', \n",
    "                'max_deal_maturity_date',\n",
    "                'adj_deal_maturity_date',\n",
    "                'deal_currency',\n",
    "                'deal_active',\n",
    "                'deal_amended', \n",
    "                'deal_amount', \n",
    "                'covenants',\n",
    "                'covlite_deal',\n",
    "                'levloan_deal',\n",
    "                'revolver_deal',\n",
    "                'revolver_amount_deal',\n",
    "                'gvkey']]\n",
    "dat_df_4 = dat_df_4.merge(tmp, on=['lpc_deal_id','tranche_active_date'], how='left', validate='many_to_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename categories\n",
    "\n",
    "dict_ = {'Max. Debt to Cash Flow': 'Max. Debt to EBITDA',\n",
    "         'Max. Sr. Debt to Cash Flow': 'Max. Senior Debt to EBITDA',\n",
    "         'Min. Interest Coverage Ratio': 'Min. Interest Coverage',\n",
    "         'Min. Fixed Charge Coverage Ratio': 'Min. Fixed Charge Coverage',\n",
    "         'Min. Debt Service Coverage Ratio': 'Min. Debt Service Coverage',\n",
    "         'Min. Cash Interest Coverage Ratio': 'Min. Cash Interest Coverage',\n",
    "         'Max. Debt to Equity Ratio': 'Max. Debt to Equity',\n",
    "         'Max. Leverage Ratio': 'Max. Leverage ratio',\n",
    "         'Tangible Net Worth': 'Tangible Net Worth',\n",
    "         'Net Worth': 'Net Worth',\n",
    "         'Min. Current Ratio': 'Min. Current Ratio',\n",
    "         'Max. Loan to Value Ratio': 'Max. Loan to Value ratio',\n",
    "         'Max. Debt to Tangible Net Worth Ratio': 'Max. Debt to Tangible Net Worth'\n",
    "         }\n",
    "\n",
    "dat_df_4['variable'] = dat_df_4['variable'].map(dict_)\n",
    "dat_df_4.rename({'variable':'covenant','covenants':'has_covenant','value': 'covthreshold'}, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_df_4.to_stata('../../data/dealscan_combined_long_new_2.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## some analysis on raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique identifiers: lpc_deal_id, tranche_active_date\n",
    "\n",
    "dat_df_2[dat_df_2.deal_amended=='Yes'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of new issues over time in Dealscan\n",
    "\n",
    "tmp = dat_df_2.copy()\n",
    "tmp['year'] = tmp.tranche_active_date.dt.year\n",
    "tmp = tmp[tmp.year.between(1994,2021)]\n",
    "tmp = tmp[tmp.fic=='USA']\n",
    "\n",
    "# tmp1 = tmp.drop_duplicates(subset=['lpc_deal_id'], keep='first')\n",
    "tmp.year.value_counts().sort_index().plot(label='new loans')\n",
    "\n",
    "tmp2 = tmp.drop_duplicates(subset='lpc_company_id', keep='first')\n",
    "tmp2.year.value_counts().sort_index().plot(label='new companies')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute average duration of loan contracts \n",
    "\n",
    "tmp['duration'] = tmp.tranche_maturity_date.dt.year - tmp.tranche_active_date.dt.year\n",
    "plot_ = tmp.groupby('year')['duration'].quantile([0.05,0.5,0.95]).loc[1994:]\n",
    "plot_ = pd.DataFrame(plot_).reset_index()\n",
    "plot_.columns=['year','quantiles','value']\n",
    "plot_ = plot_.pivot(index='year',columns='quantiles')\n",
    "plot_.columns = ['p5', 'p50','p95']\n",
    "plt.plot(plot_.index,plot_['p5'], label='p5')\n",
    "plt.plot(plot_.index,plot_['p50'], label='p50')\n",
    "plt.plot(plot_.index,plot_['p95'], label='p95')\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_df_3 = dat_df_1.copy()\n",
    "\n",
    "# adjust data type\n",
    "dat_df_3['tranche_active_date'] = pd.to_datetime(dat_df_3['tranche_active_date'], errors='coerce')\n",
    "dat_df_3['tranche_maturity_date'] = pd.to_datetime(dat_df_3['tranche_maturity_date'], errors='coerce')\n",
    "dat_df_3['deal_active_date'] = pd.to_datetime(dat_df_3['deal_active_date'], errors='coerce')\n",
    "\n",
    "dat_df_3['duration'] = dat_df_3.tranche_maturity_date.dt.year - dat_df_3.tranche_active_date.dt.year\n",
    "dat_df_3['year'] = dat_df_3.tranche_active_date.dt.year\n",
    "\n",
    "dat_df_3 = dat_df_3[dat_df_3.year.between(1994,2021)]\n",
    "# dat_df_3 = dat_df_3[dat_df_3.fic=='USA']\n",
    "\n",
    "plot_ = dat_df_3.groupby('year')['duration'].mean().loc[1994:]\n",
    "plot_ = pd.DataFrame(plot_).reset_index()\n",
    "plt.scatter(plot_['year'],plot_['duration'])\n",
    "plt.plot(plot_['year'],plot_['duration'])\n",
    "plt.xlabel('Year of origination')\n",
    "plt.ylabel('Average deal maturity (years)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = dat_df_2.copy()\n",
    "tmp = tmp[tmp.fic=='USA']\n",
    "\n",
    "tmp = tmp.drop_duplicates(subset='lpc_deal_id', keep='first')\n",
    "tmp.groupby('year')['deal_amount'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of covenants\n",
    "\n",
    "# ebc_list = ['max_debt_to_cash_flow', \n",
    "#             'max_sr_debt_to_cash_flow', \n",
    "#             'min_interest_coverage_ratio', \n",
    "#             'min_fixed_charge_coverage_ratio',\n",
    "#             'min_debt_service_coverage_ratio',\n",
    "#             'min_cash_interest_coverage_ratio']\n",
    "# abc_list = ['max_debt_to_equity_ratio',\n",
    "#             'max_leverage_ratio',\n",
    "#             'min_current_ratio',\n",
    "#             'max_loan_to_value_ratio',\n",
    "#             'max_debt_to_tangible_net_worth']\n",
    "\n",
    "# cov_list = ebc_list + abc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carryforward ratios for same trench as long as covenant == Yes (ratios not repeated if amended )\n",
    "\n",
    "# dat_df_1.sort_index(inplace=True)\n",
    "\n",
    "# for i in tqdm(cov_list):\n",
    "#     dat_df_1[i] = dat_df_1.loc[dat_df_1['covenants']=='Yes',i].groupby(level=0).fillna(method='ffill')\n",
    "\n",
    "# dat_df_1.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate variable for number of ebcs and abcs (asset based)\n",
    "# note: if tranche is amended, new entry does not record covenant unless amended, but covenants record \"Yes\"\n",
    "# see entry numbers 647:648 for comparison\n",
    "\n",
    "# dat_df_1['num_ebc'] = len(ebc_list) - dat_df_1[ebc_list].isnull().sum(axis=1)\n",
    "# dat_df_1['num_abc'] = len(abc_list) - dat_df_1[abc_list].isnull().sum(axis=1)\n",
    "# dat_df_1['covenants'] = dat_df_1.covenants.map({'Yes':1,'No':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this example, no covenants are recorded, but there is a non null entry in \"all_covenants_financial\". See lpc_tranche_id==100436\n",
    "# there are also cases where covenant = 1 but no entries in covenants or 'all_covenants_financial'. See lpc_tranche_id==100305\n",
    "\n",
    "# pd.set_option('max_columns', None)\n",
    "# dat_df_1[dat_df_1.lpc_tranche_id=='100436'].reset_index(drop=True)['all_covenants_financial'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for misclassified cases (generalizing the case above)\n",
    "# 2 percent of cases are like this\n",
    "\n",
    "# dat_df_1[((dat_df_1.num_ebc==0)&(dat_df_1.num_abc==0))&(dat_df_1.covenants==1)].shape[0] / dat_df_1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract covenant ratio from string \n",
    "# data encodes it as a string\n",
    "\n",
    "# def read_string(str_in):\n",
    "    \n",
    "#     out = None\n",
    "    \n",
    "#     str_in = np.nan_to_num(str_in, nan=-99)\n",
    "    \n",
    "#     if str_in and str_in != -99:\n",
    "#         aux = re.search(r'((?<=to ).*(?=:1))|^[.*(?=:1$)]', str_in)\n",
    "#         if aux:\n",
    "#             out = float(aux.group())\n",
    "    \n",
    "#     return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract covenant ratios\n",
    "\n",
    "# cov_list = ['max_debt_to_cash_flow', \n",
    "#             'max_sr_debt_to_cash_flow', \n",
    "#             'min_interest_coverage_ratio', \n",
    "#             'min_fixed_charge_coverage_ratio',\n",
    "#             'min_debt_service_coverage_ratio',\n",
    "#             'min_cash_interest_coverage_ratio',\n",
    "#             'max_debt_to_equity_ratio',\n",
    "#             'max_leverage_ratio',\n",
    "#             'min_current_ratio',\n",
    "#             'max_loan_to_value_ratio',\n",
    "#             'max_debt_to_tangible_net_worth']\n",
    "\n",
    "# for i in tqdm(cov_list):\n",
    "    \n",
    "#     aux = dat_df_1[i].apply(read_string)\n",
    "#     dat_df_1[i] = aux\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def custom_round(x, base=5):\n",
    "#     return base * round(float(x)/base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # second round of merging, use closest match in 5 years \n",
    "\n",
    "# dat_df_3 = dat_df_2.copy()\n",
    "# dat_df_3['year10'] = dat_df_2['deal_active_date'].apply(lambda x: custom_round(x.year, base=10))\n",
    "# dat_df_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roberts_df_2 = roberts_df_1.copy()\n",
    "\n",
    "# roberts_df_2.dropna(subset=['year'],inplace=True)\n",
    "# roberts_df_2['year10'] = roberts_df_2['year'].apply(lambda x: custom_round(x, base=10))\n",
    "# roberts_df_2.rename({'gvkey':'gvkey2'}, axis=1, inplace=True)\n",
    "\n",
    "# # if duplicated just keep latest \n",
    "# roberts_df_2.set_index(['lpc_company_id','year'], inplace=True)\n",
    "# roberts_df_2.sort_index(inplace=True)\n",
    "# roberts_df_2.reset_index(inplace=True)\n",
    "# roberts_df_2 = roberts_df_2.drop_duplicates(subset=['lpc_company_id','year10'])\n",
    "# roberts_df_2.drop(['year'],axis=1,inplace=True)\n",
    "# roberts_df_2.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat_df_3 = dat_df_3.merge(roberts_df_2, on=['lpc_company_id','year10'], validate='many_to_one', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ = dat_df_3[dat_df_3.gvkey2.isna()==True].lpc_company_id.unique()\n",
    "\n",
    "# aux = roberts_df_2[roberts_df_2.lpc_company_id.isin(list_)]\n",
    "\n",
    "# aux.shape[0] / roberts_df_2.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use first round matching (match exact year), if missing then use second round matching\n",
    "\n",
    "# dat_df_3['gvkey'] = dat_df_3['gvkey'].fillna(dat_df_3['gvkey2'])\n",
    "\n",
    "# dat_df_3.drop(['year10','gvkey2'], axis=1, inplace=True)\n",
    "\n",
    "# dat_df_3.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_ = dat_df_3[dat_df_3.gvkey.isna()==True].lpc_company_id.unique()\n",
    "\n",
    "# aux = roberts_df_2[roberts_df_2.lpc_company_id.isin(list_)]\n",
    "\n",
    "# aux.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat_df_3.gvkey.notnull().sum() / dat_df_3.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dat_df_3['tranche_maturity_date'] = pd.to_datetime(dat_df_3['tranche_maturity_date'])\n",
    "# dat_df_3['deal_active_date'] = pd.to_datetime(dat_df_3['deal_active_date'])\n",
    "# dat_df_3.to_stata('../../data/dealscan_combined_long_new.dta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
