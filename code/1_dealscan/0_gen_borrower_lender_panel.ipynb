{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Builds a borrowerâ€“lender panel from Dealscan to examine covenant-related lending patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this file analyzes Dealscan at the borrower-lender level\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from fuzzywuzzy import fuzz\n",
    "pd.set_option('display.max_columns', None)\n",
    "# pd.set_option('display.max_colwidth', None)\n",
    "# pd.set_option('display.max_rows', None)\n",
    "warnings.filterwarnings('ignore')\n",
    "tqdm.pandas()\n",
    "\n",
    "datdir = '/path/to/project/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read Dealscan data\n",
    "\n",
    "dat_df = joblib.load(datdir+'rawdata/dealscan/dealscan_new.pkl')\n",
    "\n",
    "dat_df.set_index(['lpc_tranche_id','tranche_active_date'], inplace=True)\n",
    "dat_df.sort_index(inplace=True)\n",
    "dat_df.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep relevant variables\n",
    "dscan_df = dat_df[[\n",
    "        'lender_id','borrower_id','lpc_deal_id','deal_input_date','deal_active_date','lpc_tranche_id','tranche_active_date',\n",
    "        'lender_parent_name','lender_parent_id','number_of_lenders','lender_name','tranche_maturity_date', \n",
    "        'deal_active', 'primary_role', 'additional_roles','deal_amount','deal_amount_converted','tranche_amount',\n",
    "        'deal_purpose','lender_commit','lender_share','lead_arranger','lead_left','number_of_lead_arrangers','number_of_lead_left',\n",
    "        'tranche_o_a', 'lender_institution_type', 'tranche_type', 'sic_code','market_segment',\n",
    "        'base_reference_rate','all_in_spread_drawn_bps','all_in_spread_undrawn_bps'\n",
    "        ]]\n",
    "# del dat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple deal_input_dates, keep the earliest\n",
    "dscan_df.sort_values(['lender_id','borrower_id','lpc_deal_id','deal_active_date','lpc_tranche_id','tranche_active_date','deal_input_date'], inplace=True)\n",
    "dscan_df.drop_duplicates(['lender_id','borrower_id','lpc_deal_id','deal_active_date','lpc_tranche_id','tranche_active_date'],keep='first',inplace=True)\n",
    "dscan_df.reset_index(drop=True,inplace=True)\n",
    "dscan_df.drop(['deal_input_date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dscan_df['ncount'] = dscan_df.groupby(['lender_id','borrower_id','lpc_deal_id','deal_input_date','deal_active_date','lpc_tranche_id'])['lpc_tranche_id'].transform('count')\n",
    "# count number of types the column 'tranche_o_a' takes value 'Origination' by group\n",
    "# dscan_df['norig'] = dscan_df.groupby(['lender_id','borrower_id','lpc_deal_id','deal_input_date','deal_active_date','lpc_tranche_id'])['tranche_o_a'].transform(lambda x: (x=='Origination').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# housekeeping\n",
    "dscan_df['sic_code'] = dscan_df['sic_code'].str.extract('(\\d+)', expand=False)\n",
    "dscan_df['lender_institution_type'] = dscan_df['lender_institution_type'].fillna('')\n",
    "dscan_df['tranche_type'] = dscan_df['tranche_type'].fillna('') \n",
    "dscan_df['market_segment'] = dscan_df['market_segment'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify lead arranger\n",
    "\n",
    "# check 1: identify lead arranger based on whether name of company is in list of \"lead arranger\"\n",
    "def clean_string(s):\n",
    "    s = re.sub(r'[^A-Za-z\\s]', '', s)  # Remove numbers and punctuations\n",
    "    s = re.sub(r'\\([^)]*\\)', '', s)   # Remove terms in parentheses\n",
    "    s = re.sub(r'\\[[^\\]]*\\]', '', s)   # Remove terms in brackets\n",
    "    return s.strip()\n",
    "\n",
    "def check_lead(row):\n",
    "    is_lead = 0\n",
    "    lender_name = clean_string(row['lender_name'])\n",
    "    if row['lead_arranger']:\n",
    "        lead_arrangers = row['lead_arranger'].split(', ')\n",
    "        for lead in lead_arrangers:\n",
    "            lead = clean_string(lead)\n",
    "            if fuzz.ratio(lender_name.lower(), lead.lower()) >= 90:\n",
    "                is_lead=1\n",
    "    return is_lead \n",
    "\n",
    "dscan_df['is_lead'] = dscan_df.progress_apply(check_lead, axis=1)\n",
    "\n",
    "# # check 2: identify based on role (removed - Apr 22, 2024)\n",
    "# # # relevant_terms = [\"Mandated Lead arranger\",\"Lead arranger\",\"Lead manager\",\"Co-lead manager\",\"Co-lead arranger\",\"Expanded lead manager\",\"Lead bank\",\"Lead Left\",\"Senior co-lead manager\",\"Joint lead manager\",\"Extended lead manager\"]\n",
    "# relevant_terms = [\"Mandated Lead arranger\",\"Lead arranger\",\"Co-lead arranger\",\"Mandated arranger\",\"Coordinating arranger\"]\n",
    "# dscan_df['primary_role'] = dscan_df['primary_role'].fillna('')\n",
    "# dscan_df['additional_roles'] = dscan_df['additional_roles'].fillna('')\n",
    "# dscan_df['all_roles'] = dscan_df['primary_role']+', '+dscan_df['additional_roles']\n",
    "# dscan_df.drop(columns=['primary_role','additional_roles'], inplace=True)\n",
    "# dscan_df['is_lead_2'] = dscan_df.progress_apply(lambda x: 1 if re.search('|'.join(relevant_terms), x['all_roles']) else 0, axis=1)\n",
    "\n",
    "# final classification is the max of both labels\n",
    "# dscan_df['is_lead'] = dscan_df[['is_lead_1', 'is_lead_2']].max(axis=1)\n",
    "sum_df = dscan_df.groupby(['lpc_tranche_id','tranche_active_date'])['is_lead'].sum().reset_index()\n",
    "dscan_df = dscan_df.merge(sum_df, on=['lpc_tranche_id','tranche_active_date'], suffixes=('', '_sum'))\n",
    "# dscan_df.drop(columns=['is_lead_1','is_lead_2'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  check dealid 21507 -- how many lead arrangers?\n",
    "\n",
    "# dscan_df.loc[dscan_df['lpc_deal_id']=='21507','lead_arranger'].values[0]\n",
    "# dscan_df.loc[dscan_df['lpc_deal_id']=='21507']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## identify banks vs non-banks (see Elliot, Meisenzahl, Peydro, 2021)\n",
    "\n",
    "# check lender_institution_type \n",
    "bank_terms = ['African Bank', 'Asia-Pacific Bank', 'Asian Bank', 'Australian/New Zealand Bank', 'Canadian Bank', 'East. Europe/Russian Bank', 'European Bank', 'Export-Import Bank/ECA', \n",
    "         'Farm Credit Bank', 'Foreign Bank', 'Japanese Bank', 'Latin America & Caribbean Bank', 'Middle Eastern Bank',  'Mortgage Bank', 'Thrift / S&L', 'US Bank', 'Western European Bank']\n",
    "\n",
    "def check_nonbank(row):\n",
    "    if row['lender_institution_type']=='':\n",
    "        return {'is_bank':-1, 'is_instinv':-1, 'is_mf':-1, 'institution_type': []}\n",
    "\n",
    "    # split string and count number of terms\n",
    "    type_terms = row['lender_institution_type'].split(',')\n",
    "    type_terms = [x.strip() for x in type_terms]\n",
    "\n",
    "    # check for non bank terms\n",
    "    is_bank = 0\n",
    "    is_institution = 0\n",
    "    is_mutual_fund = 0\n",
    "\n",
    "    for term in type_terms:\n",
    "        if term in bank_terms and len(term)>0: # if any bank term present, then it is a bank\n",
    "            is_bank = 1\n",
    "        if re.search('Inst. Invest.', term):\n",
    "            is_institution = 1\n",
    "        if re.search('Mutual Fund', term):\n",
    "            is_mutual_fund = 1\n",
    "        \n",
    "    return {'is_bank':is_bank, 'is_instinv':is_institution, 'is_mf':is_mutual_fund, 'institution_type': type_terms}\n",
    "\n",
    "out = dscan_df.progress_apply(check_nonbank, axis=1)\n",
    "out = pd.DataFrame(out.tolist())\n",
    "dscan_df = pd.concat([dscan_df, out], axis=1)\n",
    "\n",
    "def unique_values(x):\n",
    "    result = set()\n",
    "    for sublist in x:\n",
    "        result.update(sublist)\n",
    "    return list(result)\n",
    "\n",
    "# aggregate non_bank indicator by lender id (to handle inconsistent labeling of lender_institution_type)\n",
    "aux = dscan_df[['lender_id','lender_name','is_bank','is_instinv','is_mf','institution_type']].groupby('lender_id').agg(\n",
    "    {'lender_name':'first',\n",
    "    'is_bank':['max','size'], \n",
    "    'is_instinv':'max',\n",
    "    'is_mf':'max',\n",
    "    'institution_type':unique_values}\n",
    ").reset_index()\n",
    "aux.columns = ['lender_id','lender_name','is_bank','n_tranche','is_instinv','is_mf','institution_type']\n",
    "# aux['lender_institution_type'] = aux['lender_institution_type'].str.split(',').apply(lambda x : ', '.join(set([e.strip() for e in x])))\n",
    "# aux.to_csv(datdir+'temp.txt', index=False, sep='|')\n",
    "# aux.drop(['lender_institution_type'],axis=1).to_csv(datdir+'/data/dealscan_lenderlist.txt', index=False, sep='|')\n",
    "\n",
    "# classify lenders as bank/nonbank using aggregated list\n",
    "dscan_df.drop(['is_bank','is_instinv','is_mf','lender_institution_type','institution_type'], axis=1, inplace=True)\n",
    "dscan_df = dscan_df.merge(aux[['lender_id','is_bank','is_instinv','is_mf','institution_type']], on='lender_id', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify type of loan (see Demiroglu and James, 2016)\n",
    "\n",
    "# 1. traditional bank loans are term A loans or credit lines funded only by commercial banks or insurance companies\n",
    "trancheA_terms = ['Term Loan A', 'Revolver/Line >= 1 Yr.', 'Revolver/Line < 1 Yr.']\n",
    "commercial_lender_terms = ['African Bank', 'Asia-Pacific Bank', 'Asian Bank', 'Australian/New Zealand Bank', 'Canadian Bank', 'East. Europe/Russian Bank', 'European Bank', 'Export-Import Bank/ECA', \n",
    "         'Farm Credit Bank', 'Foreign Bank', 'Japanese Bank', 'Latin America & Caribbean Bank', 'Middle Eastern Bank',  'Mortgage Bank', 'Thrift / S&L', 'US Bank', 'Western European Bank', \"Insurance Company\"]\n",
    "inst_lender_terms = ['Inst. Invest. CDO', 'Inst. Invest. Hedge Fund', 'Private Equity','Mutual Fund']\n",
    "private_lender_terms = ['Investment Bank', 'Finance Company']\n",
    "def check_loan_type(row):\n",
    "\n",
    "    # 0. identify institution type\n",
    "    is_commercial_bank, is_inst_inv, is_inv_bank = 1, 0, 0\n",
    "    for term in row['institution_type']:\n",
    "        if term not in commercial_lender_terms: # commercial banks or insurance company with no additional classification\n",
    "            is_commercial_bank = 0\n",
    "        if term in inst_lender_terms:\n",
    "            is_inst_inv = 1\n",
    "        if term in private_lender_terms:\n",
    "            is_inv_bank = 1\n",
    "\n",
    "    # 1. identify tranche type\n",
    "    is_termA = 0\n",
    "    for term in trancheA_terms:\n",
    "        if re.search(term, row['tranche_type']):\n",
    "            is_termA = 1\n",
    "            break   \n",
    "    is_termB = 0\n",
    "    if re.search('Term Loan B', row['tranche_type']):\n",
    "        is_termB = 1\n",
    "\n",
    "    # 2. classify loans \n",
    "    trad_bank_loan, inst_loan, private_loan, inst_loan_ib = 0,0,0,0\n",
    "    if is_termA and is_commercial_bank:\n",
    "            trad_bank_loan = 1\n",
    "    if is_termB or (is_inst_inv and not is_termB and not is_inv_bank):\n",
    "        inst_loan = 1            \n",
    "    if is_termA and is_inv_bank and not is_inst_inv:\n",
    "        private_loan = 1\n",
    "    if is_termB or (not is_inst_inv and not is_termB and is_inv_bank):\n",
    "        inst_loan_ib = 1   \n",
    "\n",
    "    # 3. Berlin, Nini, Yu institutional classification\n",
    "    inst_loan_bny = 0\n",
    "    # if the loan is Term Loan B, C, or D, then inst_loan_bny = 1\n",
    "    if re.search('Term Loan [B-D]', row['tranche_type']):\n",
    "        inst_loan_bny = 1\n",
    "\n",
    "    return {'trad_bank_loan':trad_bank_loan, \"inst_loan\": inst_loan, \n",
    "            \"inst_loan_ib\": inst_loan_ib, \"private_loan\": private_loan, \n",
    "            \"termA\": is_termA, \"termB\": is_termB, \"inst_loan_bny\": inst_loan_bny}\n",
    "\n",
    "out = dscan_df.progress_apply(check_loan_type, axis=1)\n",
    "out = pd.DataFrame(out.tolist())\n",
    "dscan_df = pd.concat([dscan_df, out], axis=1)\n",
    "\n",
    "# # use value at origination\n",
    "# def replace_values(group):\n",
    "#     origination_row = group[group['tranche_o_a'] == 'Origination']\n",
    "#     if not origination_row.empty:\n",
    "#         group['trad_bank_loan'] = origination_row['trad_bank_loan'].values[0]\n",
    "#         group['inst_loan'] = origination_row['inst_loan'].values[0]\n",
    "#         group['inst_loan_ib'] = origination_row['inst_loan_ib'].values[0]\n",
    "#         group['private_loan'] = origination_row['private_loan'].values[0]\n",
    "#         group['termA'] = origination_row['termA'].values[0]\n",
    "#         group['termB'] = origination_row['termB'].values[0]\n",
    "#         group['inst_loan_bny'] = origination_row['inst_loan_bny'].values[0]\n",
    "#     else:\n",
    "#         group['trad_bank_loan'] = 0\n",
    "#         group['inst_loan'] = 0\n",
    "#         group['inst_loan_ib'] = 0\n",
    "#         group['private_loan'] = 0\n",
    "#         group['termA'] = 0\n",
    "#         group['termB'] = 0\n",
    "#         group['inst_loan_bny'] = 0\n",
    "#     return group\n",
    "# Apply the custom function within each group\n",
    "# dscan_df = dscan_df.groupby(['lpc_tranche_id']).progress_apply(replace_values).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract covlite indicator\n",
    "\n",
    "def read_marketsegment(row_in):\n",
    "    \n",
    "    leverage, covlite, institutional = 0, 0 , 0\n",
    "    \n",
    "    if re.search('leverage',row_in['market_segment'], re.IGNORECASE):\n",
    "        leverage = 1\n",
    "    if re.search('covenant lite', row_in['market_segment'], re.IGNORECASE):\n",
    "        covlite = 1\n",
    "    if re.search('institutional', row_in['market_segment'], re.IGNORECASE):\n",
    "        institutional = 1\n",
    "        \n",
    "    return {'levloan': leverage, 'covlite': covlite, 'institutional': institutional}\n",
    "\n",
    "out = dscan_df.progress_apply(read_marketsegment, axis=1)\n",
    "out = pd.DataFrame(out.tolist())\n",
    "dscan_df = pd.concat([dscan_df, out], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with lpc connector crosswalk\n",
    "\n",
    "id_df = joblib.load(datdir+'rawdata/dealscan/lpc_loanconnector_company_id_map.pkl')\n",
    "# id_df = joblib.load(datdir+'\\\\lpc_loanconnector_company_id_map.pkl')\n",
    "id_df.rename({'loanconnector_company_id':'borrower_id'}, axis=1, inplace=True)\n",
    "\n",
    "# adjust data type\n",
    "dscan_df['tranche_active_date'] = pd.to_datetime(dscan_df['tranche_active_date'], errors='coerce')\n",
    "dscan_df['tranche_maturity_date'] = pd.to_datetime(dscan_df['tranche_maturity_date'], errors='coerce')\n",
    "dscan_df['deal_active_date'] = pd.to_datetime(dscan_df['deal_active_date'], errors='coerce')\n",
    "\n",
    "# merge with old company identifiers\n",
    "dscan_df = dscan_df.merge(id_df, on='borrower_id', how='outer', indicator=True, validate='many_to_one')\n",
    "print(dscan_df._merge.value_counts())\n",
    "dscan_df = dscan_df[dscan_df._merge=='both'].reset_index(drop=True) # keep only those with exact merges\n",
    "dscan_df.drop(['_merge'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## merge with Chava-Roberts link table\n",
    "\n",
    "cv_df = pd.read_excel(datdir+\"rawdata/dealscan/Dealscan-Compustat_Linking_Database.xlsx\", sheet_name='link_data')\n",
    "# cv_df = pd.read_excel(datdir+\"\\\\Dealscan-Compustat_Linking_Database.xlsx\", sheet_name='link_data')\n",
    "cv_df = cv_df[['bcoid','gvkey','facstartdate','fic']].drop_duplicates(subset=['bcoid','facstartdate'])\n",
    "cv_df.rename({'bcoid': 'lpc_company_id','facstartdate':'tranche_active_date'}, axis=1, inplace=True)\n",
    "\n",
    "dscan_df['lpc_company_id'] = dscan_df['lpc_company_id'].astype(int)\n",
    "dscan_df = dscan_df.merge(cv_df, on=['lpc_company_id','tranche_active_date'], how='left', indicator=True, validate='many_to_one')\n",
    "print(dscan_df._merge.value_counts())\n",
    "print(dscan_df.gvkey.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carry forward gvkey values for those with previous match (assume no change)\n",
    "# dscan_df.reset_index(inplace=True, drop=False)\n",
    "dscan_df.set_index(['lpc_company_id'], inplace=True)\n",
    "dscan_df.sort_index(inplace=True)\n",
    "\n",
    "# carry backward gvkey values for those with future match \n",
    "dscan_df['gvkey'] = dscan_df['gvkey'].groupby(level=0).fillna(method='ffill')\n",
    "dscan_df['gvkey'] = dscan_df['gvkey'].groupby(level=0).fillna(method='bfill')\n",
    "\n",
    "# formatting\n",
    "dscan_df.reset_index(inplace=True)\n",
    "dscan_df.drop(['_merge'],axis=1,inplace=True)\n",
    "\n",
    "dscan_df.gvkey.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust contract maturity date for loan amendments\n",
    "\n",
    "dscan_df = dscan_df.sort_values(by=['lender_id','borrower_id','lpc_deal_id','deal_active_date','lpc_tranche_id', 'tranche_active_date'])\n",
    "\n",
    "dscan_df['adjusted_maturity_date'] = dscan_df.groupby(['lender_id','borrower_id','lpc_deal_id','deal_active_date','lpc_tranche_id'])['tranche_active_date'].shift(-1)\n",
    "dscan_df['adjusted_maturity_date'] = dscan_df.progress_apply(\n",
    "    lambda row: min(row['tranche_maturity_date'], row['adjusted_maturity_date']) # take whichever is earlier\n",
    "    if pd.notnull(row['adjusted_maturity_date']) else row['tranche_maturity_date'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "dscan_df['diff_'] = dscan_df['adjusted_maturity_date'] - dscan_df['tranche_maturity_date']\n",
    "dscan_df['diff_'] = dscan_df['diff_'].dt.days\n",
    "dscan_df['early_nego'] = np.where(dscan_df['diff_']<0, 1, 0)\n",
    "dscan_df.drop(['diff_'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flag deals with revolver tranches\n",
    "\n",
    "dscan_df['has_revolver'] = dscan_df['tranche_type'].apply(lambda x: 1 if re.search('Revolver', x) else 0)\n",
    "dscan_df['has_termloan'] = dscan_df['tranche_type'].apply(lambda x: 1 if re.search('Term Loan', x) else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)\n",
    "dscan_df.loc[dscan_df['lpc_deal_id']=='21507',['lender_id','lender_name','lpc_deal_id','lpc_tranche_id','tranche_o_a','tranche_active_date','tranche_maturity_date','tranche_type','adjusted_maturity_date','early_nego','is_lead','has_revolver','has_termloan','all_in_spread_drawn_bps']].sort_values(by=['tranche_type','lender_id','tranche_active_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deal-lender with the earliest active date and the latest maturity date\n",
    "dscan_df = dscan_df.sort_values(by=['lender_id','borrower_id','lpc_deal_id','deal_active_date','lpc_tranche_id', 'tranche_active_date'])\n",
    "deal_lender_df = dscan_df.groupby(['lender_id','borrower_id','lpc_deal_id','tranche_active_date']).agg(\n",
    "    # earliest_active_date=('tranche_active_date', 'min'), # earliest tranche lender participates\n",
    "    latest_maturity_date=('adjusted_maturity_date', 'max'), # latest maturity lender participates \n",
    "    early_nego=('early_nego', 'max'), # whether lender participated in early negotiation\n",
    "    lender_parent_name=('lender_parent_name', 'first'),  \n",
    "    lender_parent_id=('lender_parent_id', 'first'),            \n",
    "    lender_name=('lender_name', 'first'),\n",
    "    gvkey=('gvkey', 'first'),\n",
    "    sic_code=('sic_code', 'first'),\n",
    "    deal_active=('deal_active', 'last'), # whether last deal is active or not\n",
    "    lead_arranger=('is_lead', 'max'),\n",
    "    is_bank=('is_bank', 'max'),\n",
    "    is_instinv=('is_instinv', 'max'),\n",
    "    is_mf=('is_mf', 'max'),\n",
    "    deal_amount=('deal_amount', 'first'),\n",
    "    deal_amount_converted=('deal_amount_converted', 'first'),\n",
    "    tranche_o_a=('tranche_o_a', 'first'),\n",
    "    has_revolver=('has_revolver', 'max'),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrower-loan dataset\n",
    "loan_df = dscan_df.groupby(['lpc_deal_id','tranche_active_date']).agg(\n",
    "    # earliest_active_date=('tranche_active_date', 'min'), # earliest tranche lender participates\n",
    "    latest_maturity_date=('adjusted_maturity_date', 'max'), # latest maturity lender participates \n",
    "    orig_maturity_date=('tranche_maturity_date', 'min'), # original maturity date  \n",
    "    early_nego=('early_nego', 'max'), # whether deal was renegotiated early maturity date       \n",
    "    gvkey=('gvkey', 'first'),\n",
    "    borrower_id=('borrower_id', 'first'),\n",
    "    sic_code=('sic_code', 'first'),\n",
    "    trad_bank_loan=('trad_bank_loan', 'max'),\n",
    "    inst_loan=('inst_loan', 'max'),\n",
    "    private_loan=('private_loan', 'max'),\n",
    "    inst_loan_ib=('inst_loan_ib', 'max'),\n",
    "    termA=('termA', 'max'),\n",
    "    termB=('termB', 'max'),\n",
    "    levloan=('levloan', 'max'),\n",
    "    covlite=('covlite', 'max'),    \n",
    "    nlenders=('lender_id', 'nunique'),\n",
    "    institutional=('institutional', 'max'),\n",
    "    inst_loan_bny=('inst_loan_bny', 'max'),\n",
    "    deal_amount=('deal_amount', 'first'),\n",
    "    deal_amount_converted=('deal_amount_converted', 'first'),    \n",
    "    tranche_o_a=('tranche_o_a', 'first'),\n",
    "    deal_active=('deal_active', 'last'), # whether last deal is active or not\n",
    "    has_revolver=('has_revolver', 'max'),\n",
    "    has_termloan=('has_termloan', 'max'),\n",
    "    base_reference_rate=('base_reference_rate', 'first'),\n",
    "    all_in_spread_drawn_bps=('all_in_spread_drawn_bps', 'first'),\n",
    "    all_in_spread_undrawn_bps=('all_in_spread_undrawn_bps', 'first')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrower-tranche dataset \n",
    "tranche_df = dscan_df.groupby(['lpc_tranche_id','tranche_active_date']).agg(\n",
    "    # earliest_active_date=('tranche_active_date', 'min'), # earliest tranche lender participates\n",
    "    latest_maturity_date=('adjusted_maturity_date', 'max'), # latest maturity lender participates \n",
    "    orig_maturity_date=('tranche_maturity_date', 'min'), # original maturity date  \n",
    "    early_nego=('early_nego', 'max'), # whether deal was renegotiated early maturity date       \n",
    "    gvkey=('gvkey', 'first'),\n",
    "    borrower_id=('borrower_id', 'first'),\n",
    "    sic_code=('sic_code', 'first'),\n",
    "    trad_bank_loan=('trad_bank_loan', 'max'),\n",
    "    inst_loan=('inst_loan', 'max'),\n",
    "    private_loan=('private_loan', 'max'),\n",
    "    inst_loan_ib=('inst_loan_ib', 'max'),\n",
    "    termA=('termA', 'max'),\n",
    "    termB=('termB', 'max'),\n",
    "    levloan=('levloan', 'max'),\n",
    "    covlite=('covlite', 'max'),    \n",
    "    nlenders=('lender_id', 'nunique'),\n",
    "    institutional=('institutional', 'max'),\n",
    "    inst_loan_bny=('inst_loan_bny', 'max'),\n",
    "    deal_amount=('deal_amount', 'first'),\n",
    "    deal_amount_converted=('deal_amount_converted', 'first'),    \n",
    "    tranche_amount=('tranche_amount', 'first'),\n",
    "    tranche_o_a=('tranche_o_a', 'first'),\n",
    "    deal_active=('deal_active', 'last'), # whether last deal is active or not\n",
    "    has_revolver=('has_revolver', 'max'),\n",
    "    has_termloan=('has_termloan', 'max'),\n",
    "    base_reference_rate=('base_reference_rate', 'first'),\n",
    "    all_in_spread_drawn_bps=('all_in_spread_drawn_bps', 'first'),\n",
    "    all_in_spread_undrawn_bps=('all_in_spread_undrawn_bps', 'first')\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct borrower-lender level dataset\n",
    "borrower_lender_df = dscan_df.groupby(['lender_id','borrower_id']).agg(\n",
    "    earliest_active_date=('tranche_active_date', 'min'), # earliest tranche lender participates\n",
    "    latest_maturity_date=('adjusted_maturity_date', 'max'), # latest maturity lender participates \n",
    "    early_nego=('early_nego', 'max'), # whether lender has negotiated early maturity date\n",
    "    lender_parent_name=('lender_parent_name', 'first'),  \n",
    "    lender_parent_id=('lender_parent_id', 'first'),            \n",
    "    lender_name=('lender_name', 'first'),\n",
    "    gvkey=('gvkey', 'first'),\n",
    "    sic_code=('sic_code', 'first'),\n",
    "    lead_arranger=('is_lead', 'max'),\n",
    "    is_bank=('is_bank', 'max'),\n",
    "    is_instinv=('is_instinv', 'max'),\n",
    "    is_mf=('is_mf', 'max'),\n",
    "    deal_active=('deal_active', 'last'),\n",
    ").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save dataframe\n",
    "deal_lender_df.to_stata(datdir+'data/dealscan_deal_lender.dta', write_index=False)\n",
    " \n",
    "borrower_lender_df.to_stata(datdir+'data/dealscan_borrower_lender.dta', write_index=False)\n",
    "\n",
    "loan_df.to_stata(datdir+'data/dealscan_borrower_deal.dta', write_index=False)\n",
    "\n",
    "tranche_df.to_stata(datdir+'data/dealscan_borrower_tranche.dta', write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del dat_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debtcovenant",
   "language": "python",
   "name": "debtcovenant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}