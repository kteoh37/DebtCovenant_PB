{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b03218b5",
   "metadata": {},
   "source": [
    "module to get sentiment of call using Loughran-Mcdonald dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04550e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "bucket = '[bucket-name]'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tqdm.pandas()\n",
    "datdir = \"s3://{}/data/\".format(bucket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c1567e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Loughran Mcdonald sentiment dictionary\n",
    "\n",
    "dat_path = datdir+\"LoughranMcDonald_SentimentWordLists_2018.xlsx\"\n",
    "\n",
    "# read raw data\n",
    "lm_pos = pd.read_excel(dat_path, sheet_name='Positive',header=None)[0]\\\n",
    "                        .apply(lambda x: re.sub('#.*$', '', str(x).lower()))\n",
    "lm_neg = pd.read_excel(dat_path, sheet_name='Negative',header=None)[0]\\\n",
    "                        .apply(lambda x: re.sub('#.*$', '', str(x).lower()))\n",
    "\n",
    "# stem and remove duplicates\n",
    "lm_pos_stem = list(set([ps.stem(w) for w in lm_pos]))\n",
    "lm_neg_stem = list(set([ps.stem(w) for w in lm_neg]))\n",
    "\n",
    "lmdict = dict()\n",
    "lmdict['positive'] = lm_pos_stem\n",
    "lmdict['negative'] = lm_neg_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15122af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data cleaning. (use same algorithm as in extract_covconcerns)\n",
    "\n",
    "def clean_sentence(sentence, remove_stop=False, stem_words=True):\n",
    "\n",
    "    # remove formatting\n",
    "    sentence = re.sub('\\n',' ', sentence) # remove line break markers \n",
    "    sentence = re.sub('&#[0-9]+;',' ', sentence) # remove character ids\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower() \n",
    "    \n",
    "    # remove false flags\n",
    "    sentence = re.sub(r\"\\b(?:'ll|we'll|will|may|should|shouldn't|can|can't|would|wouldn't|can also|may also|will also|should also) \\b(?:increase|decrease|step down|step up|see|say|mention|recall|note|add|talk|like to)\",'', sentence)\n",
    "    sentence = re.sub('May','',sentence)\n",
    "    \n",
    "    # additional cleaning\n",
    "    sentence = re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', sentence)\n",
    "    sentence = re.sub(r'(mda|md a)','', sentence) # short form\n",
    "    sentence = re.sub(r'form\\s\\w{0,1}','',sentence) # form number\n",
    "    sentence = re.sub('table of contents','',sentence) # table of contents\n",
    "    sentence = re.sub(r'(item|i tem)\\s{0,1}[0-9]*[a-z]{0,1}','', sentence) # header\n",
    "    sentence = re.sub('(year|years) ended','', sentence)\n",
    "    sentence = re.sub('page\\s{0,1}[0-9]*','',sentence)\n",
    "    sentence = re.sub('rsquo','', sentence)\n",
    "    sentence = re.sub('amp','', sentence)\n",
    "    sentence = re.sub('rdquo','',sentence)\n",
    "    sentence = re.sub('ldquo','',sentence)\n",
    "    \n",
    "    # remove hanging characters\n",
    "    sentence = re.sub(r'(?<!\\w)\\.(?!\\w)',' ',sentence) # remove hanging .\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "    \n",
    "    # remove stopwords\n",
    "    if remove_stop:\n",
    "        word_tokens = word_tokenize(sentence)\n",
    "        word_filtered = [w for w in word_tokens if w not in stop_words]\n",
    "        sentence = ' '.join(word_filtered)\n",
    "        \n",
    "    # remove capitalization and punctuations\n",
    "    sentence = re.sub(r'\\b[b-z]\\b',' ', sentence) # remove hanging characters\n",
    "    sentence = re.sub(\"[^A-Za-z\\s]\",' ',sentence) \n",
    "    sentence = re.sub(' +',' ',sentence)   \n",
    "        \n",
    "    # stem\n",
    "    if stem_words:\n",
    "        sentence = ' '.join([ps.stem(x) for x in sentence.split()])\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d96597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to extract sentiment (Loughran-Mcdonald sentiment 2018)\n",
    "\n",
    "def compute_sentiment(sent_in, senti_dict):\n",
    "\n",
    "    # get list\n",
    "    positive_list = senti_dict[\"positive\"]\n",
    "    negative_list = senti_dict[\"negative\"]\n",
    "\n",
    "    # tokenize sentence\n",
    "    senti_score = None\n",
    "    pos_words = None\n",
    "    neg_words = None\n",
    "    if sent_in is not None:\n",
    "        sent_in = clean_sentence(sent_in, remove_stop=True, stem_words=True)\n",
    "        tokens = word_tokenize(sent_in)\n",
    "\n",
    "        # match sentiment word list\n",
    "        pos_words = set(tokens).intersection(set(positive_list))\n",
    "        neg_words = set(tokens).intersection(set(negative_list))\n",
    "\n",
    "        # count number of sentiment words\n",
    "        pos_count = sum([tokens.count(w) for w in pos_words])\n",
    "        neg_count = sum([tokens.count(w) for w in neg_words])\n",
    "        tot_count = pos_count + neg_count\n",
    "\n",
    "        # compute sentiment score\n",
    "        if (tot_count > 0) & (np.isfinite(tot_count)):\n",
    "            senti_score = np.divide(pos_count*1 + neg_count*(-1), tot_count)\n",
    "        else:\n",
    "            senti_score = 0 \n",
    "\n",
    "        # conver ttype\n",
    "        senti_score = np.nan_to_num(senti_score)\n",
    "        pos_words = list(pos_words)\n",
    "        neg_words = list(neg_words)\n",
    "\n",
    "    return senti_score, pos_words, neg_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f38864d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN PROGRAM\n",
    "\n",
    "#### 1. READ DATA\n",
    "filepath = datdir+'factset_calls_covconcerns_v6.gzip'\n",
    "df = pd.read_parquet(filepath)\n",
    "\n",
    "# run sentiment on all covenant sentences\n",
    "covmention_senti = df['covenant_text'].progress_apply(lambda x: compute_sentiment(x, lmdict))\n",
    "covmention_senti = list(zip(*covmention_senti))\n",
    "\n",
    "# run sentiment on covconcern sentences\n",
    "covconcern_senti = df['covconcern_text'].progress_apply(lambda x: compute_sentiment(x, lmdict))\n",
    "covconcern_senti = list(zip(*covconcern_senti))\n",
    "\n",
    "# save data\n",
    "df['cov_senti'] = covmention_senti[0]\n",
    "df['cov_pos_words'] = covmention_senti[1]\n",
    "df['cov_neg_words'] = covmention_senti[2]\n",
    "df['covcon_senti'] = covconcern_senti[0]\n",
    "df['covcon_pos_words'] = covconcern_senti[1]\n",
    "df['covcon_neg_words'] = covconcern_senti[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e282a926",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check quality\n",
    "\n",
    "test = df[df.cov_senti>0].sample(n=5).reset_index()\n",
    "test\n",
    "for i in range(5):\n",
    "    \n",
    "    print(test.loc[i,'cov_senti'])\n",
    "    print(test.loc[i,'cov_pos_words'])\n",
    "    print(test.loc[i,'cov_neg_words'])\n",
    "    print(test.loc[i,'covenant_text'])\n",
    "    print('\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667fce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# export sentiment data \n",
    "\n",
    "df1 = df[['date','repid','cov_senti','covcon_senti']]\n",
    "df1 = df1.fillna(0)\n",
    "\n",
    "savepath = datdir+'factset_calls_covconcerns_sentiment_v6.txt'\n",
    "df1.to_csv(savepath, sep='|')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918099be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
