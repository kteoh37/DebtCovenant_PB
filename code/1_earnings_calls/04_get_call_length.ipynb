{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d84400",
   "metadata": {},
   "source": [
    "This module gets length of call (number of words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d76727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import multiprocessing\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "import numpy as np\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "import io\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "bucket = '[your-bucket-name]'\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "stop_words = set(stopwords.words('english'))\n",
    "tqdm.pandas()\n",
    "datdir = \"s3://{}/data/\".format(bucket)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1591059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic data cleaning. (use same algorithm as in extract_covconcerns)\n",
    "\n",
    "def clean_sentence(sentence, remove_stop=False, stem_words=True):\n",
    "\n",
    "    # remove formatting\n",
    "    sentence = re.sub('\\n',' ', sentence) # remove line break markers \n",
    "    sentence = re.sub('&#[0-9]+;',' ', sentence) # remove character ids\n",
    "    sentence = sentence.strip()\n",
    "    sentence = sentence.lower() \n",
    "    \n",
    "    # remove false flags\n",
    "    sentence = re.sub(r\"\\b(?:'ll|we'll|will|may|should|shouldn't|can|can't|would|wouldn't|can also|may also|will also|should also) \\b(?:increase|decrease|step down|step up|see|say|mention|recall|note|add|talk|like to)\",'', sentence)\n",
    "    sentence = re.sub('May','',sentence)\n",
    "    \n",
    "    # additional cleaning\n",
    "    sentence = re.sub(r\"\\b(?=[mdclxvii])m{0,4}(cm|cd|d?c{0,3})(xc|xl|l?x{0,3})([ii]x|[ii]v|v?[ii]{0,3})\\b\\.?\", '', sentence)\n",
    "    sentence = re.sub(r'(mda|md a)','', sentence) # short form\n",
    "    sentence = re.sub(r'form\\s\\w{0,1}','',sentence) # form number\n",
    "    sentence = re.sub('table of contents','',sentence) # table of contents\n",
    "    sentence = re.sub(r'(item|i tem)\\s{0,1}[0-9]*[a-z]{0,1}','', sentence) # header\n",
    "    sentence = re.sub('(year|years) ended','', sentence)\n",
    "    sentence = re.sub('page\\s{0,1}[0-9]*','',sentence)\n",
    "    sentence = re.sub('rsquo','', sentence)\n",
    "    sentence = re.sub('amp','', sentence)\n",
    "    sentence = re.sub('rdquo','',sentence)\n",
    "    sentence = re.sub('ldquo','',sentence)\n",
    "    \n",
    "    # remove hanging characters\n",
    "    sentence = re.sub(r'(?<!\\w)\\.(?!\\w)',' ',sentence) # remove hanging .\n",
    "    sentence = re.sub(' +',' ',sentence)\n",
    "    \n",
    "    # remove stopwords\n",
    "    if remove_stop:\n",
    "        word_tokens = word_tokenize(sentence)\n",
    "        word_filtered = [w for w in word_tokens if w not in stop_words]\n",
    "        sentence = ' '.join(word_filtered)\n",
    "        \n",
    "    # remove capitalization and punctuations\n",
    "    sentence = re.sub(r'\\b[b-z]\\b',' ', sentence) # remove hanging characters\n",
    "    sentence = re.sub(\"[^A-Za-z\\s]\",' ',sentence) \n",
    "    sentence = re.sub(' +',' ',sentence)   \n",
    "        \n",
    "    # stem\n",
    "    if stem_words:\n",
    "        sentence = ' '.join([ps.stem(x) for x in sentence.split()])\n",
    "\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to get number of sentence and number of words\n",
    "\n",
    "def get_call_length(doc_in):\n",
    "    # doc_in is a string containing the content of the call\n",
    "    \n",
    "    nsents = 0\n",
    "    nwords = 0\n",
    "    \n",
    "    if len(doc_in) > 0:\n",
    "        \n",
    "        # clean text\n",
    "        doc_clean = clean_sentence(doc_in, remove_stop=True, stem_words=True)\n",
    "        \n",
    "        # calculate number of tokens\n",
    "        nwords = len(word_tokenize(doc_in))\n",
    "    \n",
    "    return {\n",
    "        'nwords': nwords,\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "yearstart = int(input('start year: '))\n",
    "yearend = int(input('end year: '))\n",
    "yearlist = range(yearstart,yearend+1)\n",
    "\n",
    "for yr in reversed(yearlist):\n",
    "\n",
    "    # read in earnings calls data\n",
    "    print(f'loading data from year {yr}')\n",
    "\n",
    "    # read file\n",
    "    s3_client = boto3.client('s3')\n",
    "    file = f\"factset_calls/raw_{yr}.gzip\"\n",
    "    obj = s3_client.get_object(Bucket=bucket,Key=file)\n",
    "    df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "    \n",
    "    # combine mda and qa section\n",
    "    print('combining mda and qa...')\n",
    "    raw_text = df.progress_apply(lambda x: x['mda']+x['qa'],axis=1)\n",
    "    df.drop(['mda','qa'],axis=1,inplace=True)\n",
    "    df['raw_text'] = raw_text\n",
    "    \n",
    "    # extract covmentions\n",
    "    print('extracting call length...')\n",
    "    query = Parallel(n_jobs=multiprocessing.cpu_count(), batch_size=32) \\\n",
    "            (delayed(get_call_length)(text) for text in tqdm(df['raw_text'])) \n",
    "    query = pd.DataFrame(query)\n",
    "    df1 = df.join(query)\n",
    "    \n",
    "    # append to main data frame\n",
    "    df1.drop(['raw_text'],axis=1,inplace=True)\n",
    "    df_all = df_all.append(df1, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c69f9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prefix = f's3://{bucket}/output/'\n",
    "savepath = output_prefix +'factset_call_length_postsubmit.txt'\n",
    "wr.s3.to_csv(\n",
    "    df=df_all,\n",
    "    path=savepath,\n",
    "    sep='|'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
