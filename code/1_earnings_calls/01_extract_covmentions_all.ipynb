{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56d84400",
   "metadata": {},
   "source": [
    "This module extracts snippets from earnings calls with mentions of covenants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d76727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import awswrangler as wr\n",
    "from nltk.stem import PorterStemmer\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import numpy as np\n",
    "import io\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "\n",
    "ps = PorterStemmer()\n",
    "bucket = '[bucket_name]'  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bc10c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# module to extract covenant mentions\n",
    "# input: document as a string\n",
    "# output: sentences with covenant mentions as a string\n",
    "\n",
    "def get_covmentions(doc_in):\n",
    "    # doc_in is a string containing the content of the call\n",
    "    \n",
    "    covmentions_raw = ''\n",
    "    \n",
    "    # tokenize document\n",
    "    sentences = sent_tokenize(doc_in)\n",
    "    \n",
    "    # remove boilerplate\n",
    "    if len(sentences)>10:\n",
    "        sentences = sentences[10:]\n",
    "\n",
    "    if len(sentences) > 0:\n",
    "        \n",
    "        regex = r'covenant|convenant'\n",
    "        mask = pd.Series(sentences).str.contains(regex)\n",
    "        covmentions_raw = ' '.join(pd.Series(sentences)[mask])\n",
    "    \n",
    "    return covmentions_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455a02cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.DataFrame()\n",
    "\n",
    "yearstart = int(input('start year: '))\n",
    "yearend = int(input('end year: '))\n",
    "yearlist = range(yearstart,yearend+1)\n",
    "\n",
    "for yr in reversed(yearlist):\n",
    "\n",
    "    # read in earnings calls data\n",
    "    print(f'loading data from year {yr}')\n",
    "\n",
    "    # read file\n",
    "    s3_client = boto3.client('s3')\n",
    "    file = f\"factset_calls/raw_{yr}.gzip\"\n",
    "    obj = s3_client.get_object(Bucket=bucket,Key=file)\n",
    "    df = pd.read_parquet(io.BytesIO(obj['Body'].read()))\n",
    "\n",
    "    # combine mda and qa section\n",
    "    print('combining mda and qa...')\n",
    "    raw_text = df.progress_apply(lambda x: x['mda']+x['qa'],axis=1)\n",
    "    df.drop(['mda','qa'],axis=1,inplace=True)\n",
    "    df['raw_text'] = raw_text\n",
    "\n",
    "    # extract covmentions\n",
    "    print('extracting covenent mentions...')\n",
    "    df['covmentions_raw'] = df.raw_text.progress_apply(get_covmentions)\n",
    "    df.drop(['raw_text'],axis=1,inplace=True)\n",
    "    \n",
    "    # append to main data frame\n",
    "    df_all = df_all.append(df, ignore_index=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdd879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output \n",
    "\n",
    "output_prefix = f's3://{bucket}/factset_calls_covmentions/'\n",
    "savepath = output_prefix + f'covmentions_all_v6.gzip'\n",
    "wr.s3.to_parquet(\n",
    "    df=df_all,\n",
    "    path=savepath,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd30895",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
