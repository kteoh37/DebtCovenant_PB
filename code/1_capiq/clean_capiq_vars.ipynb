{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir= '/path/to/project/'\n",
    "rawdir = maindir + 'rawdata_jfi_fin/capiq/'\n",
    "outdir = maindir + 'data_jfi_fin/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_capiq(filepath, var):\n",
    "    \n",
    "    df = pd.read_excel(filepath, sheet_name=var, header=2)\n",
    "    \n",
    "    # keep relevant rows\n",
    "    mask = (df['SP_ENTITY_ID'].notnull()) & (df['IQ_GVKEY'].notnull()) & (df['SP_CIQ_ID'].notnull())\n",
    "    df = df[mask].reset_index(drop=True)\n",
    "\n",
    "    # Expand out GVKEY\n",
    "    df['gvkey'] = df['IQ_GVKEY'].str.split(',')\n",
    "    df_expanded = df.explode('gvkey').drop(['IQ_GVKEY'], axis=1)\n",
    "    \n",
    "    # Create indicators for company status\n",
    "    acquired_status = ['Acquired']\n",
    "    liquidated_status = ['Out of Business', 'Liquidating', 'Reorganizing', 'No Longer Investing']\n",
    "    \n",
    "    df_expanded['iq_acquired'] = df_expanded['SP_COMPANY_STATUS'].isin(acquired_status).astype(int)\n",
    "    df_expanded['iq_liquidated'] = df_expanded['SP_COMPANY_STATUS'].isin(liquidated_status).astype(int)\n",
    "    \n",
    "    # Define aggregation rules\n",
    "    aggregation_rules = {\n",
    "        col: 'max' if np.issubdtype(df_expanded[col].dtype, np.number) else 'first'\n",
    "        for col in df_expanded.columns if col != 'gvkey'\n",
    "    }\n",
    "\n",
    "    # Group by GVKEY and aggregate\n",
    "    df_unique = df_expanded.groupby('gvkey').agg(aggregation_rules).reset_index()\n",
    "    \n",
    "    # Reshape to long format\n",
    "    df_long = pd.wide_to_long(df_unique, stubnames='FQ', i='gvkey', j='fyq_str').reset_index()\n",
    "    \n",
    "    # Select and rename relevant columns\n",
    "    df_long = df_long[['gvkey', 'fyq_str', 'iq_acquired', 'iq_liquidated', 'FQ']]\n",
    "    df_long.rename(columns={'FQ': var}, inplace=True)\n",
    "    \n",
    "    # Construct fiscal quarter variables\n",
    "    df_long['fyq_str'] = df_long['fyq_str'].astype(str)\n",
    "    df_long['fyearq'] = df_long['fyq_str'].str[1:]\n",
    "    df_long['fqtr'] = df_long['fyq_str'].str[0]\n",
    "    df_long['gvkey'] = df_long['gvkey'].str[3:]\n",
    "    df_long.drop(['fyq_str'], axis=1, inplace=True)\n",
    "    \n",
    "    return df_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract excel files\n",
    "\n",
    "filepath = rawdir + 'CapIQ_CreditLine_Vars.xlsx'\n",
    "iq_rc = clean_capiq(filepath, 'IQ_RC')\n",
    "iq_cp = clean_capiq(filepath, 'IQ_CP')\n",
    "iq_tl = clean_capiq(filepath, 'IQ_TERM_LOANS')\n",
    "iq_undrawn_credit = clean_capiq(filepath, 'IQ_UNDRAWN_CREDIT')\n",
    "iq_undrawn_rc = clean_capiq(filepath, 'IQ_UNDRAWN_RC')\n",
    "iq_undrawn_tl = clean_capiq(filepath, 'IQ_UNDRAWN_TL')\n",
    "iq_undrawn_cp = clean_capiq(filepath, 'IQ_UNDRAWN_CP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge files\n",
    "\n",
    "dfmain = iq_rc\n",
    "\n",
    "dfmain = dfmain.merge(iq_cp[['gvkey','fyearq','fqtr','IQ_CP']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n",
    "dfmain = dfmain.merge(iq_tl[['gvkey','fyearq','fqtr','IQ_TERM_LOANS']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n",
    "dfmain = dfmain.merge(iq_undrawn_credit[['gvkey','fyearq','fqtr','IQ_UNDRAWN_CREDIT']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n",
    "dfmain = dfmain.merge(iq_undrawn_rc[['gvkey','fyearq','fqtr','IQ_UNDRAWN_RC']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n",
    "dfmain = dfmain.merge(iq_undrawn_tl[['gvkey','fyearq','fqtr','IQ_UNDRAWN_TL']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n",
    "dfmain = dfmain.merge(iq_undrawn_cp[['gvkey','fyearq','fqtr','IQ_UNDRAWN_CP']], on=['gvkey','fyearq','fqtr'], validate='1:1', how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder\n",
    "dfmain = dfmain[[\n",
    "    'gvkey','fyearq','fqtr','iq_acquired','iq_liquidated',\n",
    "    'IQ_RC','IQ_CP','IQ_TERM_LOANS','IQ_UNDRAWN_CREDIT',\n",
    "    'IQ_UNDRAWN_RC','IQ_UNDRAWN_TL','IQ_UNDRAWN_CP'\n",
    "                ]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formatting\n",
    "collist = [\n",
    "    'IQ_RC','IQ_CP','IQ_TERM_LOANS','IQ_UNDRAWN_CREDIT',\n",
    "    'IQ_UNDRAWN_RC','IQ_UNDRAWN_TL','IQ_UNDRAWN_CP'    \n",
    "]\n",
    "for c in collist:\n",
    "    dfmain[c] = dfmain[c].astype(float) \n",
    "\n",
    "dfmain['fyearq'] = dfmain['fyearq'].astype(int)\n",
    "dfmain['fqtr'] = dfmain['fqtr'].astype(int)\n",
    "\n",
    "dfmain.columns = [x.lower() for x in dfmain.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmain.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = outdir + 'CapIQ_CreditLine_Vars_processed.dta'\n",
    "dfmain.to_stata(filepath, write_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmain.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
